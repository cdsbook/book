[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An Introduction to Computing and Data for Scientists",
    "section": "",
    "text": "Preface\nPreface."
  },
  {
    "objectID": "src/book/01_intro.html#what-are-the-computational-and-data-sciences",
    "href": "src/book/01_intro.html#what-are-the-computational-and-data-sciences",
    "title": "1  Introduction",
    "section": "1.1 What are the computational and data sciences?",
    "text": "1.1 What are the computational and data sciences?\nIn this book we are concerned with two closely related fields:\n\nComputational science (also called scientific computing) combines computer science (i.e. the theory of how computers work) with applied problems.\nData science similarly combines statistics (i.e. the mathematical theory of analyzing data) with applied problems.\n\nBasically we want to know how to apply computers and data to solve real world problems.\nThere are problems in the world that we could choose to address with computers and data. In this book we will focus on problems from the natural and social sciences (i.e. physics, biology, economics, psychology, etc.)."
  },
  {
    "objectID": "src/book/01_intro.html#why-this-book",
    "href": "src/book/01_intro.html#why-this-book",
    "title": "1  Introduction",
    "section": "1.2 Why this book?",
    "text": "1.2 Why this book?\nMany books on these topics (particularly data science) are interested in business problems. Businesses are typically concerned with learning about the future, typically in the interest of making more profit tomorrow.\nThere is nothing inherently wrong with this, and indeed scientists are sometimes interested in predicting the future as well. However scientists are more generally interested in the broader goal of understanding how the world works. W\nAlthough scientists and business people have to worry about many of the same problems when dealing with computers and data, our different end goals mean that we put more emphasis on different parts of the process.\nAs scientists, we want to learn the underlying truths of the universe.\n\nWe want to make sure that any discoveries we make are real (we don’t want to fool ourselves, a pit that is surprisingly easy to fall into). We therefore care about making sure that our experiments are reproducible. (I.e. if we have discovered something real, any other scientist should be able to follow our steps to get to the same result.)\nSince we care about understanding over prediction, we prefer simpler mathematical approaches that are easier to interpret.\nAs scientists we should try to focus on simplicity and clarity over glamour!\n\nThat’s not to say that a data scientist at a company shouldn’t care about reproducibility, simplicity, and clarity. But if a company can make a million dollars tomorrow with a sexy but complicated and hard-to-reproduce analysis, then they should do so! But this would be bad practice for a scientist."
  },
  {
    "objectID": "src/book/01_intro.html#reproducibility",
    "href": "src/book/01_intro.html#reproducibility",
    "title": "1  Introduction",
    "section": "1.3 Reproducibility",
    "text": "1.3 Reproducibility\nThe rest of this book is focused on how to use computers and data in ways that are good scientific practice. However, let us take a moment to talk more about the importance of reproducibility.\nUnfortunately, scientists are not rewarded for making sure that their analyses are reproducible, or for checking that they can reproduce the work of other scientists.\nIn a recent survey of 1500 scientists (Baker 2016), a shockingly high percentage said that they were unable to reproduce another scientist’s work:\n\n\n\n\n\nFigure 1.1: Data from (Baker 2016).\n\n\n\n\nConsider how the process of modern science works:\n\nThe scientist needs to get money to pay for their future work, so they apply for grants. In the USA, a lot of grant money is distributed by the federal government; other grants may come from private organizations. However, there is never enough money for every scientist who applies, and so the grant distributors have to pick their favorites. And what makes a proposal likely to be funded? Doing exciting, new research (not routine reproduction of other scientists existing work).\nEven if you decide to reproduce an experiment, its not always simple to do so. Scientists are supposed to describe the steps they followed in their experiment, but they do not always provide enough details for somebody else to replicate their work exactly. Sometimes, scientists can’t even reproduce their own work (this is not uncommon in laboratory experiments in chemistry or biology, where you are working with minuscule substances that you hope are in your test tubes, but which might be subtly different from one day to the next).\nIn the computational and data sciences, there are often subtle choices we can make in terms of parameter values, or choice of algorithm, or simply the way that you write your code, which can significantly alter the output of your computer program. Thus you may also need the original computer code that was used for the analysis!\nIf the experiment is the analysis of an existing dataset, then anyone wishing to reproduce the work will need access to the same data and code. Unfortunately, scientists do not always make their data or code available when they publish their results.\n\nSometimes this is for good reasons (e.g. protecting the privacy of the people in the dataset, or not publishing the genetic sequence of a dangerous virus).\nOther times the reasons might be more self-serving. For example, if you were able to get a large grant of money to do a difficult experiment, you might want to publish several different analyses of the results. Unfortunately there are no prizes for second place in science, and the first person to make a discovery gets the glory. If somebody else publishes a discovery that you were about to publish yourself, then scientists call this getting “scooped”. To avoid getting scooped, you might decide to restrict access to your data until you have published all the analyses of it that you want to.\nYou can restrict data access in responsible ways, typically by publishing the data at the same time as your study but placing an embargo on it. This delays the publication of the data, typically by several months or years, until you have had a chance to publish your other analyses, but ensures that it will eventually become available to any other scientists who want to check your work or extend upon it.\nAnd sometimes scientists don’t have a good reason for not publishing their data/code, except that it wasn’t required of them1. Fortunately this attitude is now changing, as science as changed its incentives around reproducibility. For example:\n\n\nIn the USA, the federal government has started to require that any science done using its grants has to make data available when results are published.\nNew initiatives like the Center for Open Science2 are promoting the sharing of data and code, for example by creating the Open Science Framework3 for new studies\n\n\nThere are now various websites that will permanently archive code and data so that it can be easily shared with other researchers, such as DataDryad and FigShare.\n\n\n\n\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a."
  },
  {
    "objectID": "src/book/01_intro.html#footnotes",
    "href": "src/book/01_intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a problem of both the scientists as well as science as a discpline.↩︎\nhttps://www.cos.io/↩︎\nhttps://osf.io/↩︎"
  },
  {
    "objectID": "src/book/02_setup.html#code-editors",
    "href": "src/book/02_setup.html#code-editors",
    "title": "2  Setup",
    "section": "2.1 Code editors",
    "text": "2.1 Code editors\nProgramming code is typically written in plain text files (but instead of the file extension .txt they will typically use a different extension that indicates the programming language being used). Traditionally, code in the R programming language was written in R script files with the .R file extension.\nBecause these code files are just text, all you need to open them is a text editor, like Windows’s Notepad or Mac’s TextEdit. However, you can also use a dedicated code editing program, which will add a lot of useful features that makes writing code much easier. These editing programs are often called Interactive Development Environments, but because that is a mouthful, we usually just refer to them using their acronym: IDEs.\nThe most popular IDE for the R programming language is called RStudio, and there are two easy ways to use it.\n\nDownload and install the free RStudio Desktop version to your computer.\nUse the online Posit Cloud1 version through a web browser (no installation required, but only free for a certain number of hours each month2).\n\nThese two versions are functionally equivalent, so the only things you really have to decide is how averse you are to paying money and whether you can install software on the computer you are using.\n\nHow to pick the best RStudio editor for you.\n\n\n\n\n\n\n\n\nDon’t want to pay\nCan pay if necessary\n\n\n\n\nCan install software\nInstall RStudio Desktop.\nEither works.3\n\n\nCan’t install software\nUse Posit Cloud online, and don’t exceed the monthly free quota.\nUse Posit Cloud.\n\n\n\nLater in this chapter I will give instructions for getting each of these options up and running.\nThere are also other IDEs that you can use to write R code. A popular general IDE is VS Code, which can be used to write in any different programming language. The downside is that it lacks a lot of R specific features that you can find in RStudio. However, instructions to get set-up with VS Code are provided in an Appendix: Section B.3."
  },
  {
    "objectID": "src/book/02_setup.html#version-control",
    "href": "src/book/02_setup.html#version-control",
    "title": "2  Setup",
    "section": "2.2 Version control",
    "text": "2.2 Version control\nMost programming is not actually that difficult, once you learn how to think like a computer. The hard part of programming is writing large complicated programs with other programmers.\nOne of the reasons this is challenging is because we need a way to collaboratively edit the same set of files that contain our code.\nThis is not just a problem for programmers - if you and a friend were writing a report together in Microsoft Word, you might find yourself emailing the Word document back-and-forth. In fact, Microsoft Word has helpful a feature called Track Changes that allows you to see who has edited different parts of a file.\nUnfortunately, you can’t edit the file while your friend is, otherwise you will end up with different versions of the document, and the only way to recombine them will be to compare them side-by-side and manually copy over any differences.\nIn these modern times, you could instead use an online collaborative program like Google Docs - but while that is fine for text, programs need to be run, and that usually needs you and your friend to be working on separate computers so that your versions of the code don’t interfere with each other when running.\nSoftware engineers have come up with solutions to these problems, which they call version control (because it enables you to control the version of the program that you are running). The dominant version control software used today is called Git, and it is so popular that IDE’s like RStudio automatically include integrations to work with it.\nWe will talk more about how Git works in Chapter 10 but for now you can think of it as like the save points in a video game. When you reach a significant point (like adding an important software feature, or defeating a boss in a video game) you can save your progress at that point. This allows you rewind your progress back to that point if you make a mistake in the future.\nGit can also figure out how to automatically combine different versions of a project (i.e. your version and your friend’s version), and it will keep track of all the changes you record in a save point as well as who made them.\nWe can also use websites like GitHub.com to share projects that are managed with Git. This is useful for a number of reasons, but from a reproducibility perspective it allows other scientists to download our code and run it for themselves."
  },
  {
    "objectID": "src/book/02_setup.html#step-1-create-a-github-account",
    "href": "src/book/02_setup.html#step-1-create-a-github-account",
    "title": "2  Setup",
    "section": "2.3 Step 1: Create a GitHub account",
    "text": "2.3 Step 1: Create a GitHub account\nIf you already have a GitHub account, then proceed to step 2.\nIf not, then go to https://github.com and create a free account. A few suggestions:\n\nIf you have any interest in working in tech in the future, then pick something vaguely professional as your GitHub username. You don’t want to have to explain to a future employer why your GitHub username is squeaky_boi. Think of your GitHub profile as the the programming equivalent of your LinkedIn profile.\nGitHub will ask if you want to upgrade to a fancy paid account when you register, but you should stick with the free account which has everything we need.\nGitHub will also ask you a bunch of questions when you sign up about what you want to use it for. It really doesn’t matter what you respond to these questions, so feel free to skip through them."
  },
  {
    "objectID": "src/book/02_setup.html#step-2-set-up-rstudio",
    "href": "src/book/02_setup.html#step-2-set-up-rstudio",
    "title": "2  Setup",
    "section": "2.4 Step 2: Set up RStudio",
    "text": "2.4 Step 2: Set up RStudio\n\n2.4.1 Option 1: Install RStudio Desktop on your computer\nIf you are installing RStudio Desktop on your computer, then you should follow these steps:\n\nFirst, you should first install Git by following the appropriate installation instructions for your operating system on the Git website: https://git-scm.com/downloads\n(Note that Git is almost certainly already installed if you are using Linux.)\nNext you should install R by going to the appropriate page for your operating system:\n\nWindows: download and install R from the .exe installer on this page: https://cran.rstudio.com/bin/windows/base/\nThen also install RTools from this page (make sure the version number of RTools matches the version number of R that you just installed, e.g. if you installed R v4.2.3 then you will need to install RTools v4.2 [i.e. the same first two digits]): https://cran.rstudio.com/bin/windows/Rtools/\nMac: download and install R from the appropriate .pkg installer for your version of macOS on this page: https://cran.rstudio.com/bin/macosx/\nLinux: follow the instructions for your flavor of Linux: https://cran.rstudio.com/\n\nFinally we are can install RStudio Desktop. Download the installer for your operating system here and then install from it: https://posit.co/download/rstudio-desktop/\nNote that RStudio Desktop is free, but Posit (the company that created RStudio) also offers several paid versions, so make sure you get the free RStudio Desktop version.\nAfter you have installed RStudio, you should be able to start the program, which should look like this:\n\nNext we need to install a program called (pronounced “lay-tek” - this will turn our files containing R code into nicely formatted PDFs).\nTo do this, open RStudio. There should be a pane on the left called “Console”. In this Console, copy and paste the following two lines and hit enter to run them:\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n\nOnce you have done this, proceed to Section 2.5 to connect GitHub to RStudio.\n\n\n2.4.2 Option 2: Create an online RStudio account at Posit Cloud\nGot to https://posit.cloud/ and create an account. You can sign up for the free plan, which at the time of writing includes 25 hours of online RStudio access per month before they ask you to pay.\nTo connect your GitHub account, click on your profile name/icon in the top right of the posit.cloud homepage, and then on the Authentication page.\nFind the line on this page where it says GitHub, and slowly click any unchecked checkboxes (wait a couple of seconds between each checkbox in case a prompt appears).\nSome of the checkboxes may open up new webpages taking you to GitHub, which will ask you to verify that you want to authorize Posit to access your GitHub account. Make sure you agree all of these, otherwise you might not be able to edit code on GitHub."
  },
  {
    "objectID": "src/book/02_setup.html#sec-rstudio-github-connection",
    "href": "src/book/02_setup.html#sec-rstudio-github-connection",
    "title": "2  Setup",
    "section": "2.5 Step 3: Connect RStudio to GitHub",
    "text": "2.5 Step 3: Connect RStudio to GitHub\n\n\nFirst, go to RStudio (or launch a new empty RStudio project if you are using the online RStudio at posit.cloud) and open the tab in the left hand pane called Terminal. If you do not see a Terminal tab, then you can create one from the top menu of RStudio Desktop by going to “Tools &gt; Terminal &gt; New Terminal”.\nIn this terminal, set your GitHub username by running this line, making sure to replace your name inside the quotation marks:\ngit config --global user.name \"Your Name Here\"\nThen run this commend, again making sure to replace the email inside the quotation marks with the same email you used to sign up for GitHub:\ngit config --global user.email \"you@emailHost.com\"\nI would also recommend running one final line in the Terminal (this will enable your computer to store your GitHub login details - otherwise you will be typing them in a lot).\ngit config --global credential.helper store\nThen go to the Console tab (which should be next to the Terminal), and copy and paste these lines of R code one at a time:\ninstall.packages(c(\"usethis\",\"gitcreds\"))\nthen this line (which will open a GitHub web page - see below for what to fill in)\nusethis::create_github_token()\n\nOn the token webpage that appears, make sure that you are creating a “Classic token”, and not a “Fine-grained” token. Then you will need to set the following options:\n\nIn the Note field, write something that indicates where this token will be used, e.g. RStudio.\nFor the expiration date, pick a date about in the future after which you will no longer need the token. E.g. if you are following these instructions for a class, pick a date after the end of the semester.\nYou should not select no expiration date - that is a security risk.\n\nYou can leave all the checked scopes as the defaults (you need the first set of repo scopes), and then scroll down to the green Generate token button at the bottom of the webpage and click it.\nThe next page that appears will display a token, a random series of letters and numbers that is basically a temporary password that you can use to authorize a restricted set of activities on your GitHub account (without having to share your master password with RStudio). You will never see this token again after you leave this page, so don’t close the webpage until you have finished this section, or you will have to create an entirely new token.\nReturn to the Console tab in RStudio, and run this line:\ngitcreds::gitcreds_set()\nAt the prompt, copy and paste the token from GitHub and click enter.\n(If you ever need to replace the token, just run gitcreds::gitcreds_set() in the RStudio Console again.)"
  },
  {
    "objectID": "src/book/02_setup.html#footnotes",
    "href": "src/book/02_setup.html#footnotes",
    "title": "2  Setup",
    "section": "",
    "text": "Formerly known as RStudio Cloud.↩︎\nAt the time of writing, you get 25 hours per month for free, after which you have to pay.↩︎\nBear in mind that RStudio Cloud can only be used if you are connected to the internet, so if you want to work somewhere without internet then you will need to install RStudio Desktop. Also, RStudio Desktop will ultimately provide you with more flexibility.↩︎"
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#data",
    "href": "src/book/03_r_programming_chapter.html#data",
    "title": "3  Introduction to R",
    "section": "3.1 Data",
    "text": "3.1 Data\nThe central component of everything we will be doing in R this semester is data. Even non-data science programs revolve around data.\nAt a very basic level, a computer is just a fancy calculator that adds and subtracts numbers. Even things like words and pictures are stored inside a computer as numbers.\nHowever, we often want to work work with data that is not numbers. For example, in the last section we were able to get R to print out the sentence Hello, World! To your computer that was just numbers flowing down wires as electrical signals. But the R programming language took care of converting our instruction into something your computer could understand.\nThis is the magic of programming languages! They allow us to write commands in (relatively) human-readable instructions, and then take care of translating that into the very unreadable numbers that computers work with.\nR allows us to work with several “higher-level” types of data. These data types include:\n\nthe numeric data type holds numbers such as 42 or -12.5 or 0. Unlike text, numbers are written without quotation marks around them.\nthe character data type holds text (i.e. letters, symbols, and the characters that represent numbers). We need to put the text inside quotation marks so that R knows where the text starts and ends: \"this is character data\".\n\nNote: in other programming languages this datatype is sometimes known as a “character string” or just a “string”.\n\nthe Boolean data type holds a value that is either TRUE or FALSE. (This is sometimes also referred to as the logical data type.)\n\n\n\n\nExercise: What data type is \"Introduction to Computing and Data for Scientists\"?\n\n\n\n\nExercise: Type the number 2 into the RStudio console. Hit the  key to run this line of code. What do you get back?\n\n\n\n\nExercise: What data type is FALSE? In the RStudio Console, type in typeof(FALSE), and hit the  key to run this line of code. What do you get back?\n\n\n\n\n\n\nTip\n\n\n\ntypeof() tells us the data type of any data we put inside the brackets. (Technically it is a function - we will learn more about these soon.)"
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#operators",
    "href": "src/book/03_r_programming_chapter.html#operators",
    "title": "3  Introduction to R",
    "section": "3.2 Operators",
    "text": "3.2 Operators\n\n3.2.1 Combining data with operators\n\nOkay, now we know about data.\nBut data by itself is not especially useful. It just sits there until you do something to it. There are many ways of doing things to data, but some of the simplest are operators.\nOperators operate on data. You may not have heard the name operator before, but you are already familiar with many operators, such as + and - for adding and subtracting numbers.\n\n\n\nExercise: Try it yourself: Try entering a number after the &gt; in the Console (e.g. 1), then Enter, and see what happens.\n\nWhen you hit enter, the R interpreter reads in the line, evaluates it, and returns the answer. In this case, you entered 1, so the computer thinks ‘Hey, it’s a 1! Wow, a one! The result of 1 is… drum roll, please… 1!’ and returns the result of this expression, which is a one.\nCool! But not, I confess, particularly useful. Let’s fix that: next we’ll add two numbers together.\n\nAt the prompt, enter two numbers separated by a plus sign, +\n&gt; 1 + 1\nWhat do you get?\n\n(Note that I’ve left the Console’s &gt; prompt in the example code above, but I will leave it out in future.)\n\n\n\n\nGreat! Let’s move on and investigate operators in more depth…\n\n\n3.2.2 Operating on numbers\nHeart surgeons operate on hearts, brain surgeons operate on brains. You will be operating on numbers… does that make you a data surgeon?\nHere are some of the operators available to us in R:\n\n\n\nOperator\nExample\nResult\n\n\n\n\n+\n5 + 2\n7\n\n\n-\n5 - 2\n3\n\n\n*\n5 * 2\n10\n\n\n/\n5 / 2\n2.5\n\n\n^\n5 ^ 2\n25\n\n\n%%\n5 %% 2\n1\n\n\n\nSome of these might seem obvious, while others might be unfamiliar. In this section’s exercises we will go through them all and figure out what they do.\n\n\n3.2.3 Which operator goes first?\nJust like in normal math, we can do sums in R with multiple operators:\n3 + 5 / 5 * 3 ^ 2\nIn such a case, which operation do we do first?\nAgain, just like in regular math, some operations are always done before others. For example, all multiplication and division will be done before any addition or subtraction.\n\nF.Y.I.\nThe order in which operators are calculated is known as operator precedence, and you can find the precedence of any operator here: https://stat.ethz.ch/R-manual/R-devel/library/base/html/Syntax.html\n\nWe can change the order of operations with parentheses: ( and ). For example\n2 + 2 * 5 = 12\nwhereas\n(2 + 2) * 5 = 20\n\n\n\n3.2.4 The - operator\n\n\n\nExercise: In the R Console, type 5 - 2 and hit enter to run the line of code.\nYou probably have a good idea of what - does, but try changing the numbers just to make sure!\n\n\n\n\n\n3.2.5 The * operator\n\n\n\nIn the R Console, type 3 * 2 and hit enter to run the line of code.\nWhat does * do?\n\n\n\n\n\n3.2.6 The / operator\n\n\n\nIn the R Console, type 3 / 2 and hit enter to run the line of code.\nWhat does / do? Just to be sure, try some other numbers.\n\n\n\n\n\n3.2.7 The ^ operator\n\n\n\nIn the R Console, type 3 ^ 2 and hit enter to run the line of code.\nWhat does ^ do? Try some other numbers like 2 ^ 3 or 16 ^ 0.5\n\n\n\n\n\n3.2.8 The %% operator\n\n\n\nNext up, a slightly trickier one, type 3 %% 2 and hit enter to run the line of code.\nWhat does %% do? You will probably have to try some other numbers to figure this one out.\nIf you have difficulty try also dividing the same numbers. E.g. try both 9 %% 4 and 9 / 4.\n\n\n\n\n\n\nModify this R code\n3 + 5 / 5 * 2 ^ 2\nso that it performs the calculation $\frac{3 + 5}{(5 imes 2) ^ 2}$.\nWhen correct, you should get the answer 0.08."
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#storing-and-reusing-results-with-variables",
    "href": "src/book/03_r_programming_chapter.html#storing-and-reusing-results-with-variables",
    "title": "3  Introduction to R",
    "section": "3.3 Storing and reusing results with variables",
    "text": "3.3 Storing and reusing results with variables\nSo far we have learnt how to combine data to get different results.\nWe can do multiple separate calculations by putting each one on a separate line. When R reads your code, it treats everything on one line as a single expression that is separate from other lines:\n2 + 2\n5 * 5\nThis program will have two separate outputs: 4 and 25\nHowever, after these results are shown to us, they are thrown away! All that effort just discarded…\nWhat if we wish to save the result of a calculation so that we can reuse it in a subsequent line?\nIn this case, we need to store the result in a variable.\n\n\n\nRun these two lines of code in the RStudio Console and see what result you get.\na &lt;- 2 + 2\n5 * a\nThen take a look at the Environment tab in the top-right pane of RStudio. Do you see a variable called a? Does it hold the value calculated in the first line of code or the second?\n\n\n\n\n3.3.1 The “result” of the assignment operator\nWe store the result of an expression in a variable using the assignment operator: &lt;-\nvariable_name &lt;- value_to_be_stored\n\n\n\nRun these two lines of code in the RStudio Console and see what result you get.\n2 + 3\nb &lt;- 2 + 4\nIf you take another look at the Environment tab in the top-right pane of RStudio, you should see another variable called b. What value does it hold?\n\n\n\n\n\n2 + 3\n\n\nb &lt;- 2 + 4\n\n\nThe second line of code should not print out any output when it runs. This is because assigning the result of an expression to a variable has no “result” in itself. For example, in math \\(2+2\\) is \\(4\\), but the expression \\(b = 2 + 2\\) does not return \\(4\\) directly (but somebody somewhere is hopefully keeping track of the fact that \\(b\\) is now equivalent to \\(4\\)).\nIf you want to see the data that is stored in a variable, you can put the name of the variable on a line by itself:\nsome_variable\nR will evaluate this line: it will ask itself “What is the result of some_variable”, which is just whatever value is stored in that variable.\nFor example,\n\nc &lt;- 3\n\nc\n\n[1] 3\n\n\nThe other implication of this is that if you calculate something in R and do not assign the result to a variable then it will be printed out and then forgotten. So remember: if you calculate something important in R that you will need in the future, make sure that you store that result in a variable.\n\n\n\nType the name of one of the variables in your Environment tab in the RStudio Console (e.g. a), and hit Enter to run it.\nDoes this return the data that you think is stored in that variable?\n\n\n\n\n\n\n\n3.3.2 Variables are… variable\nVariables get their name because their value can vary. We have created the variable b that holds the value 6, but we can change the value of b and store a completely different value in it!\n\n\n\nTry assigning the value 7 to the variable b using the assignment operator &lt;-.\nSince we already created b in an earlier exercise, you should see that its value in the Environment tab updates.\n\n\n\n\n\nb &lt;- 7\n\n\n\n\n\n3.3.3 When does assignment happen\n&lt;- is an operator, just like + or *. As such, it has a precedence: it will happen before some operators but after others.\nHowever, it turns out that the &lt;- precedence is extremely low - i.e. it will happen after the result of all the other operators on that line of code have been calculated.\nSo, when you write:\na &lt;- 2 + 4\n…you are essentially doing this:\na &lt;- (2 + 4)"
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#how-r-works",
    "href": "src/book/03_r_programming_chapter.html#how-r-works",
    "title": "3  Introduction to R",
    "section": "3.4 How R works",
    "text": "3.4 How R works\n\n\nR is an interpreted programming language.\nThat is a fancy way of saying that R runs (i.e. “interprets”) every line of code one at a time.\nSo far we have written a line of code and then run it. In a couple of exercises you may have run multiple lines of code where one line depended on a result from a previous line. However, R completely finished running the first line before moving onto the next one.\nWhen R interprets a line of code, it figures out how to convert your human-readable code into computer-readable instructions (which are a series of 0s and 1s, since a computer is basically a bunch of wires that can either have an electrical current flowing down them (which we denote as 1) or not (0)).\nBecause R is interpreted line-by-line, it is an ideal programming language for exploring and analyzing scientific data, where we typically figure out what to do next as we go along!\n\nTODO: Expressions and how they are evaluated. Lines and files.\n\nWe will soon be learning how to write multiple lines of R code in a file and then run them from the file. However, even when R runs code from a file, it still figures out how to run it one line at a time.\n\n\n\n\n\n\nTip\n\n\n\nCompiled Programming Languages\nNot every programming language is interpreted like R. Some are compiled.\nThis means that you write all your code in a file, and then turn all of it into computer-readable instructions at once. This step is called compilation and can take a long time (up to hours for large programs in some languages!). It is typically slower to write programs in a compiled language because of this extra step.\nThe main advantage of a compiled programming language is that your computer can figure out how to optimize all the lines of code so that they run extremely fast.\nFamous examples of compiled programming languages are Java and C++."
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#boolean-data",
    "href": "src/book/03_r_programming_chapter.html#boolean-data",
    "title": "3  Introduction to R",
    "section": "3.5 Boolean data",
    "text": "3.5 Boolean data\n\n3.5.1 Boolean data revisted\nAt the start of this chapter we mentioned that there is a type of data in R, called Boolean data, that can have one of two values: TRUE or FALSE.\nWe can ask R questions that have a true or false answer, for example: “Does the variable x hold the number 3?” or “Is 10 greater than 9?”\nWe do this with Boolean operators:\n\n\n\nOperator\nExample\nResult\n\n\n\n\n&lt;\n10 &lt; 9\nFALSE\n\n\n&gt;\n10 &gt; 9\nTRUE\n\n\n==\nx == 3\nFALSE\n\n\n\nFor example:\n\n10 &lt; 9\n\n[1] FALSE\n\n\nHere R returns the value FALSE when it evaluates this expression, because 10 is obviously not less than 9.\n\nCombining comparisons\nSometimes we want to know if one datum is greater than or equal to another. You can use the Boolean operators &gt;= for such a comparison, or &lt;= to see if something is less than or equal to another.\n\nJust as with numeric data, we can store a Boolean value in a variable, e.g. d &lt;- FALSE or e &lt;- 10 &lt; 9. (Remember that assignment always happens last, after we have evaluated the expression on the right-hand side.)\n\n\n\n3.5.2 The &lt; and &gt; operators\n\n\n\nExercise: Try it yourself: What do you get if you run 10 &lt; 9 in the RStudio Console?\nCan you change one of the numbers so that this expression returns TRUE?\nThen change the &gt; to a &lt; operator (i.e. reverse its direction). What is the result now?\n\n\n\n\n\n3.5.3 The == operators\n\n\n\nLet’s try another Boolean operator. What do you get if you run 8 == 10? What about 8 == 8?\nWhat do you think the == operator does?\n\n\n\n\nCombining comparisons\nSometimes we want to know if one datum is greater than or equal to another. You can use the Boolean operators &gt;= for such a comparison, or &lt;= to see if something is less than or equal to another.\n\n\n\n\nAssign the value TRUE to a variable called d.\n\n\n\n\n\n d &lt;- TRUE"
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#vectors",
    "href": "src/book/03_r_programming_chapter.html#vectors",
    "title": "3  Introduction to R",
    "section": "3.6 Vectors",
    "text": "3.6 Vectors\nSo far we have looked at pieces of data by themselves:\n\na &lt;- 1\nb &lt;- 2\nc &lt;- 3\nprint(a)\n\n[1] 1\n\nprint(b)\n\n[1] 2\n\nprint(c)\n\n[1] 3\n\n\nBut what about if we want to combine multiple pieces of data together?\nR includes several types of container that can hold multiple pieces of data. We can then refer to that container by a single variable. For example, instead of the three variables above, we can create a vector that holds all three values. We create a vector with c(...), putting the objects we want to combine inside the parentheses (and separated by commas):\n\nc(1,2,3)\n\n[1] 1 2 3\n\n\nAll the data in a vector must be the same type of data. For example, a vector could contain all numbers, or all characters, but not a mix of the two.\n\n\n\nCreate a vector holding 3 character strings (in this order): “This”, “is a”, “vector!”\n\n\n\n\n\nc(\"This\", \"is a\", \"vector!\")\n\n\n\nYou might be wondering what the numbers in square brackets at the start of each line in the output mean? E.g. [1]\nThese tell us where abouts in the vector we are. The number indicates the position in the vector of the first element displayed on that line.\nFor example, the [1] at the start of the line (before “Introduction”) shows that “Introduction” is the first element in this vector.\n\n\n3.6.0.1 Operations on vectors\nWe can use operators on more complicated data structures just as we did on the simpler data types. For example, we can add 2 vectors together:\n\nv1 &lt;- c(1,2,3)\nv2 &lt;- c(4,5,6)\nv1 + v2\n\n[1] 5 7 9\n\n\nAs you can see, the individual elements are added together.\n\n\n\nWhat happens if you add two vectors of different lengths? For example, run this code and see what happens:\n\n\n\nv3 &lt;- c(10, 20, 30, 40, 50)\nv4 &lt;- c(1, 2)\nv3 + v4\n\n\nWhat happens when you add two v3 and v4?\nFirstly, we get a warning \"longer object length is not a multiple of shorter object length\" because v3 is longer than v4. However, a warning doesn’t stop the code running - it merely tells us that something unexpected might be happening.\nIn this particular case, R will do something called recycling which repeats the shorter vector over and over until it is the same length as the longer vector. I.e. v4 will be repeated 2.5 times to become (1,2,1,2,1) before adding it to v3.\nR warns you that this is happening because this may not be what you wanted, especially if you hadn’t realized that the vecotrs were different lengths.\n\n\n\n\nv3 &lt;- c(10, 20, 30, 40, 50)\nv4 &lt;- c(1, 2)\nv3 + v4"
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#functions",
    "href": "src/book/03_r_programming_chapter.html#functions",
    "title": "3  Introduction to R",
    "section": "3.7 Functions",
    "text": "3.7 Functions\nPerhaps, keen mathematician that you are, you want to calculate the length of the hypotenuse of a triangle. Dredging up memories of early math classes, you will doubtless recall Pythagoras’s theorem that the hypotenuse (the long side) of triangle is given by:\n\\(c = \\sqrt{a^2 + b^2}\\)\n(\\(c\\) is the hypotenuse [long side] and \\(a\\) and \\(b\\) are the short sides.)\n\n\n\nLet’s say we have a triangle where the shorter sides (a & b) are 3 and 4 units long. Can you calculate the length of side c in R using just the operators from the first section?\nHint #1: The square root is equal to the 0.5 power of a number: 4 ^ 0.5 = 2\nHint #2: Just like in regular math equations, R will calculate some operators before others. For example it will do all multiplications before any additions. However, just like in regular math, we can change the order of operations by wrapping parts of our calculation in parentheses: (...)\n\nDid you get the answer 5? Fantastic!\n\n\n\n\n\n3.7.1 Re-useable code = functions\nWhat’s that? Another complaint? You have to write out this long expression every time you need the hypotenuse of a triangle? (No doubt this is a frequent chore in your day-to-day life.)\nAgain, there is a solution! R allows us to save pieces of code in variables. Yes, you heard that right: variables don’t just have to store data, they can also store code!\nThese stored, reusable sections of code are called functions.\nFor example, you could create a function to calculate the sum of two numbers:\nadder &lt;- function(number1, number2) {\n    result &lt;- number1 + number2\n    return(result)\n}\nEntering these 4 lines at the console prompt will be slow and error-prone, so let’s try something different.\nClick on the “File” menu at the top of RStudio. Select “New File” and then “R Script”. A blank editor window should appear in a new pane above the console.\nCopy the adder function from the previous page into this empty script. Then press “Control + Alt + R” on your keyboard (simultaneously). This will run the contents of your script all at once.\nIf successful, you should see that adder appears in the Environment pane under a new section called Functions.\nHow do we use our adder function? Go back to the console, and type something like this:\n\nadder(3, 5)\n\nIf your function is working correctly you should get the result of the 2 numbers that you entered inside the braces.\nLet’s take another look at the adder function to understand what’s going on:\nadder &lt;- function(number1, number2) {\n    result &lt;- number1 + number2\n    return(result)\n}\nLine 1: The first line creates a new function with the function keyword and saves it to the name adder using the assignment operator &lt;-, just as we did for variables.\nAfter function are a pair of parentheses. Inside these, we put a list of the parameters that the function can take, separated by commas. In this case, our adder function has two paramters (the numbers to add together). We are going to give these numbers the temporary names number1 and number2 (creative, I know). We will use these parameter names inside the function to refer to these two numbers.\nWe end the line with an opening curly bracket { to indicate that the code that follows is part of the function.\nLine 2: This is the meat of our adder function. We add our two number paramters together and store them in a variable called result. Its important to note that result only exists inside the curly brackets of the adder function (i.e. it vanishes after the function has finished).\nLine 3: Here we specify what the function is should return: in this case we want to return the result variable.\nLine 4: We signal the end of the function with a closing curly bracket (matching the one from the end of line 1).\nYou might object (and not without reason) that our adder function is a very trivial example. Wouldn’t it just be easier to use the + operator?\nYes, it would! So let’s look at a more complicated function.\nWe can create a function to calculate the hypotenuse like this:\n\nhypotenuse &lt;- function(a, b) {\n  c &lt;- (a^2 + b^2)^0.5\n  return(c)\n}\n\nThen we can use this hypotenuse function as many times as we like. For example calculate the hypotenuse of a triangle with sides of length 3 and 4, we would run:\n\nhypotenuse(3, 4)\n\n[1] 5\n\n\n\n\n\nUse the hypotenuse() function to calculate the area of a triangle with sides of length 3 and 4.\nHint: Try changing the numbers inside the parentheses after hypotenuse.\n\nDid you get the answer 5? Fantastic!\n\n\n\n\nhypotenuse &lt;- function(a, b) {\n  c &lt;- (a^2 + b^2)^0.5\n  return(c)\n}\n\n\n\n\n3.7.2 How the hypotenuse function works\nThere are a few things to note about this code:\n\nWe tell R that we are creating a reusable function using the function keyword.\nfunction is followed by parentheses (...) that contain parameters. Parameters are the names that we give to the input data to the function.\n\nFor example, above we created two parameters: a and b\nYou can have as many parameters as you want in a function, from zero on up. They must be separated by commas.\n\nThe reusable code goes inside a pair of curly brackets {...}\n\nWe can now use the function’s parameters in this code (e.g. a and b). Essentially we temporarily create new variables with the parameter names (but these are)\n\nAt the end of the function we can return a particular result with return(...) - just replace the dots with a value or\nWe store the function in a name with the assignment operator &lt;- (just like we did with variables)\nWhen we want to run the code, we write the function name followed by parentheses, with any arguments inside the parentheses (separated by commas)\n\n\n\n\nReplace the blanks to create a function to calculate the area of a triangle instead. Save this function as triangle_area.\n_______ &lt;- function(a, b) { area &lt;- _______ return(area) }\nHint: The area of a triangle is \\(0.5 imes a imes b\\)."
  },
  {
    "objectID": "src/book/03_r_programming_chapter.html#packages",
    "href": "src/book/03_r_programming_chapter.html#packages",
    "title": "3  Introduction to R",
    "section": "3.8 Packages",
    "text": "3.8 Packages\nFunctions are clearly useful - we can save a lot of time and effort by writing our code once as a function, and then just calling that function whenever we need to do that thing.\nOf course, we can save even more time by not writing the function ourselves but instead using a function that somebody else has written which does what we want.\nIn R (as in many other programming languages) we can import collections of functions (and other useful things, such as datasets) that other people have written. These collections are called packages.\n\n3.8.1 Installing packages\nBy default R will come with several useful packages installed. You can which ones are currently installed by going to the Packages tab of the bottom right pane in RStudio.\nTo install a new package, either:\n\nClick on the Install button in the Packages tab, and type the name of the package you want into to the pop-up that appears.\nGo to the RStudio Console and type in (making sure to replace the name of the package you want inside the quotes!):\ninstall.packages(\"some_package_name\")\nFor example, to install a package called the tidyverse (which we will be using for much of this book), you would run:\ninstall.packages(\"tidyverse\")\nHaving gone through this chapter, this code should hopefully make some sense! install.packages() is a function (built-in to the core R programming language), and \"tidyverse\" is a character string that we are passing as the argument to that function.\n\nNote that it can take some time to install a package (e.g. the tidyverse package can take 10-15 minutes to install!), so it’s worth checking to see if it is already installed before you waste a lot of time.\n\n\n3.8.2 Loading packages\nA package only needs to be installed to your computer once.\nHowever, you need to load the functions and other objects from that package in every R session that you wish to use them (because they will not automatically be available to R even after you have installed them).\nTo load a package we use the library() function. For example, to load the tidyverse package, you would run:\nlibrary(tidyverse)"
  },
  {
    "objectID": "src/book/04_rmarkdown_chapter.html#the-scientific-method",
    "href": "src/book/04_rmarkdown_chapter.html#the-scientific-method",
    "title": "4  Literate Programming & Reproducibility",
    "section": "4.1 The Scientific Method",
    "text": "4.1 The Scientific Method\nWhy don’t we still believe that the sun is the chariot wheel of the ancient Greek god Apollo as he drives across the sky?\nWhy do we now have effective medicines and treatments for many illnesses that were a death sentence for our ancestors?\nThe answer, in case you haven’t guessed, is science. There are many different fields of science, and each field has different techniques and ways of conducting their investigations. However the unifying feature is that all scientists share a set of rules for how that game of science is played, which is called the scientific method.\nThere is not actually a single universally agreed upon definition of what the scientific method actually is, but broadly speaking it follows these principles:\n\nA scientific theory or hypothesis must make predictions about how the world behaves.\nWe test these theories by doing experiments that have the ability to disprove them.\nWe can only choose between theories based on the outcomes of these experiments.\n\nWhat this looks like in practice can vary widely: a biologist could be out in the field observing living organisms or in the laboratory looking at cells; a physicist might be coming up with precise mathematical theories or building a telescope to go into space to observe distant galaxies; an economist might be collecting data about people’s behavior.\nIn the 21st century, a unifying feature of all of these scientists is that they are probably using computers to analyze their data or run experiments. The scientific method tells us very little about how we should go about using computers, so let us consider how we might do so."
  },
  {
    "objectID": "src/book/04_rmarkdown_chapter.html#reproducibility-and-replicability",
    "href": "src/book/04_rmarkdown_chapter.html#reproducibility-and-replicability",
    "title": "4  Literate Programming & Reproducibility",
    "section": "4.2 Reproducibility and replicability",
    "text": "4.2 Reproducibility and replicability"
  },
  {
    "objectID": "src/book/04_rmarkdown_chapter.html#how-reproducible-is-modern-science",
    "href": "src/book/04_rmarkdown_chapter.html#how-reproducible-is-modern-science",
    "title": "4  Literate Programming & Reproducibility",
    "section": "4.3 How reproducible is modern science?",
    "text": "4.3 How reproducible is modern science?"
  },
  {
    "objectID": "src/book/04_rmarkdown_chapter.html#what-we-can-do",
    "href": "src/book/04_rmarkdown_chapter.html#what-we-can-do",
    "title": "4  Literate Programming & Reproducibility",
    "section": "4.4 What we can do",
    "text": "4.4 What we can do\n\nOpen Science Foundation: https://osf.io/\n\nIncludes replication studies, e.g.\n\nCancer Biology reproducibility project: https://osf.io/collections/rpcb/discover e.g. https://osf.io/nbryi/\nPsychology reproducibility project: https://osf.io/ezcuj/wiki/home/"
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#the-good-the-bad-and-the-ugly",
    "href": "src/book/05_visualization_chapter.html#the-good-the-bad-and-the-ugly",
    "title": "5  Visualizing Data",
    "section": "5.1 The Good, the Bad, and the Ugly",
    "text": "5.1 The Good, the Bad, and the Ugly\nThis video will introduce you to the importance of visualization in data science, and how it can be used effectively (or ineffectively).\n\n\n\n\n\n\nCaution\n\n\n\nTODO: New video.\n\n\n\n\nSlides: PDF\nThere are many ways that we can visualize the same data. These pictures of data are called “graphs”. Some of these ways may be good, but many of them will be bad.\n\nA picture is worth thousand words…\n\n…and a good graph is clearer than a table of data.\nIn pre-modern times, our ancestors did not have to worry about tables of data (or words). But they did have to interpret patterns in what they saw.\nWe are stuck with the same brains, and so while a column of numbers doesn’t mean much, if we can transform that column into a picture then patterns can become much clearer.\nWhy create graphs?\n\nTo quickly understand patterns in the data.\nTo spot problems in the data (outliers, or checking that data makes sense with your expectations)\n\n\n5.1.1 Example: Challenger Disaster\nIn 1985 the space shuttle Challenger exploded shortly after launch, killing all the astronauts on-board. An investigation found that this was probably because a rubber seal had become too cold and brittle, due to cold weather on the launch day.\nThe investigation also found that although the managers and engineers knew that this was a potential issue, they had decided to go ahead with the launch anyway. But the engineers presented their concerns to their managers in the form of tables of numbers like this. Would you have looked at this and thought “Clearly we should not launch today?”\n\n\n\nTable of O-ring damage presented to NASA by Morton Thiokol’s engineers\n\n\nVisualization expert Edward Tufte suggested that clearer methods of presenting the data, such as a graph like this one, could have made a stronger case for delaying the launch:"
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#data-in-r",
    "href": "src/book/05_visualization_chapter.html#data-in-r",
    "title": "5  Visualizing Data",
    "section": "5.2 Data in R",
    "text": "5.2 Data in R\nBefore we begin to make our own graphs, we need to learn some terminology for describing the underlying data.\n\n\n\n\nSlides: PDF\n\nWe usually want to store numerical data in tables, just like you might do with spreadsheet software like Microsoft Excel or Google Sheets. For example, instead of the separate x_coords and y_coords vectors from the graph in the previous sections, we would often be working with these as separate columns of a single table:\n\n\nTable 5.1: Table of our 2 points\n\n\nx_coords\ny_coords\n\n\n\n\n1\n2\n\n\n3\n4\n\n\n\n\nBecause the R programming language is designed for analyzing data, it comes with a built-in data structure for storing tables of data: the dataframe.\nWe will learn how to create dataframes later in this book. For now, I will just give you pre-existing dataframes that we can analyze. If you want to follow along with these examples in RStudio, you can run this line of code in the Console:\nThat creates an R variable called df that holds the table of our two points. If we enter the name of the variable at the Console, R will print out the dataframe stored in the variable:\n\ndf\n\n  x_coords y_coords\n1        1        2\n2        3        4\n\n\nAs you can see, this contains the same data as the table above, albeit not formatted quite as nicely (the default formatting of dataframes in R is not particularly pretty, but that is another thing we will learn to do in the future!).\nOur dataframe is broken down into various parts:\n\nEach row represents an observation of some thing. For example, the first row represents measurements taken from one thing, and the second row represents measurements taken from a different thing.\nEach column represents a different variable, or quantity that we are measuring.\n\nNote that we are reusing the word variable here. We have already encountered one type of variable in the R programming language, as a way to store and reference objects and data in our computer.\nNow we have encountered a new use: variables as measurements from the real world, which exist as a columns in a table.\nThese two concepts of a variable are different, even though we use the same word, “variable” to refer to each of them. I will be using “variable” for both of them throughout this book, and you will need to deduce from the context whether I am talking about a programming variable in R or a column variable that measures something in the real world. (If it could be ambiguous, I might refer to an “R variable” or a “column” to prevent confusion.)\nThe columns of an R dataframe are actually vectors! I.e. a dataframe is essentially just a bunch of vectors of the same length. This means that the rules that apply to a vector also apply to a dataframe column. For example, a dataframe column can only contain one type of data (e.g. just numbers, or just character strings), just like a vector.\nWe can get a single column from a dataframe using the $ operator after the dataframe’s variable. For example, to refer to the x_coords column from our df dataframe, we could write:\n\ndf$x_coords\n\n[1] 1 3\n\n\nAnd we get back a vector of the two values from that column!\n\n\nWe have already talked about the specific types of data that the R programming language is aware of, such as numbers, character strings, and Boolean values.\nBut there are also more abstract concepts of data that a column variable can contain. For example:\n\nContinuous variables: we say that a column variable is continuous if it can feasibly be any number. For example, measurements of the height of different humans is continuous, because you could be 200cm tall, or 201cm tall, or 200.5cm tall, or 200.75cm tall (etc.). The values between any two values are also valid values for a continuous variable to take on.\nDiscrete variables: we say that a variable of numbers is discrete if it can only contain particular values. For example, the year is discrete, because it could be 2023 or 2024, but it cannot be 2023.5.\n\nCount variables are a particular sub-type of discrete variable. As you might guess from the name, this is when the variable indicates how many there are of something.\n\nCategorical variables contain labels, text, or something other than numbers. For example, colors (red, blue, green, etc.) would be categorical values.\n\nCategorical variables can be unordered, such as the color example, or…\nThey can be ordered, in which case we refer to them as ordinal variables. For example, if a variable of ratings can contain the values “good”, “average”, or “bad”, then this would be considered an ordinal variable since there is an ordering to these values.\n\n\nHere is how these different abstract types of variables could be concretely recorded in R in the columns of a dataframe (note that we have not yet encountered all of these R data types):\n\n\n\nType of variable\nType of R data\n\n\n\n\nContinuous\nNumerical\n\n\nDiscrete/count\nNumerical, integer (p. ??)\n\n\nCategorical\nNumerical, character, factor (p. ??)"
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#one-numerical-variable-histograms",
    "href": "src/book/05_visualization_chapter.html#one-numerical-variable-histograms",
    "title": "5  Visualizing Data",
    "section": "5.3 One numerical variable: histograms",
    "text": "5.3 One numerical variable: histograms\nHow can we visualize a single column of data by itself? And why would we want to do this?\n\nLet’s use a dataset that is included in the tidyverse R package which contains information about different characters from the Star Wars franchise.\n\nYou can load the dataset in RStudio by loading the tidyverse package (which you installed in Section 3.8.1) by running library(tidyverse). The dataset will then be available to you as a dataframe stored in an R variable called starwars.\nHere is an example of the data stored in the starwars dataframe: ::: {.cell hash=‘05_visualization_chapter_cache/html/unnamed-chunk-5_069e7b90eee93c4d5945aac111f22bcd’}\nstarwars\n\n# A tibble: 87 × 14\n   name        height  mass hair_…¹ skin_…² eye_c…³ birth…⁴ sex   gender homew…⁵\n   &lt;chr&gt;        &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;  \n 1 Luke Skywa…    172    77 blond   fair    blue       19   male  mascu… Tatooi…\n 2 C-3PO          167    75 &lt;NA&gt;    gold    yellow    112   none  mascu… Tatooi…\n 3 R2-D2           96    32 &lt;NA&gt;    white,… red        33   none  mascu… Naboo  \n 4 Darth Vader    202   136 none    white   yellow     41.9 male  mascu… Tatooi…\n 5 Leia Organa    150    49 brown   light   brown      19   fema… femin… Aldera…\n 6 Owen Lars      178   120 brown,… light   blue       52   male  mascu… Tatooi…\n 7 Beru White…    165    75 brown   light   blue       47   fema… femin… Tatooi…\n 8 R5-D4           97    32 &lt;NA&gt;    white,… red        NA   none  mascu… Tatooi…\n 9 Biggs Dark…    183    84 black   light   brown      24   male  mascu… Tatooi…\n10 Obi-Wan Ke…    182    77 auburn… fair    blue-g…    57   male  mascu… Stewjon\n# … with 77 more rows, 4 more variables: species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;, and abbreviated variable names\n#   ¹​hair_color, ²​skin_color, ³​eye_color, ⁴​birth_year, ⁵​homeworld\n\n:::\nWe might be interested in visualizing the heights of different Star Wars characters. Maybe we want to know if there are lots of tall characters and not many short ones.\nA graph of a single variable shows us the distribution of that variable. A good type of graph to visualize the distibution of a single continuous variable (like the height column) is a histogram.\nHere is how we can create a histogram of the height column with the plot() function:\n\nhist(x = starwars$height)\n\n\n\n\nNote how:\n\nWe used the $ operator to select the height column as a vector of numbers to go on the x-axis.\nThe x-axis of heights has been broken up into a series of bars which we call bins.\nThe length of each bin is the number of observations (the “frequency”) that fall into that bin (i.e. the number of Star Wars characters with a height in the range of that bin).\n\nFor example, the tallest bin catches the characters with a height between about 160-180 centimeters (cm). There seem to be about 28 characters in the dataset with a height in that range. (If you prefer the old Imperial measurement system, then 2.5cm is about 1 inch, so 100cm = 3’4”, 150cm = 5’, 200cm = 6’8”, etc.)\n\n\nR has guessed the number of bins for us. Sometimes you will want to customize this, and we can override the default by setting the breaks parameter of the hist() function. For example, we can force the histogram to contain just 5 bins:\n\nhist(x = starwars$height, breaks = 5)\n\n\n\n\nR will recalculate the range of the new bins, and recount how many observations fall into each bin.\n\nExercise: Find the tallest bin in the 5-bin histogram. What is the range of heights of Star Wars characters in this bin? Approximately how many characters are in this bin? Recall that one of the purposes of a graph is to see if the data fits our expectations - does this make sense as the most common height range to find in the Star Wars movies?\nWe can also create a histogram with a lot of bins, e.g. 100 bins:\n\nhist(x = starwars$height, breaks = 100)\n\n\n\n\nPicking the right number of bins is a bit like Goldilocks tasting porridge: there’s a sweet spot in the middle, but it’s a bit subjective.\n\nIf we have too few bins then we destroy any patterns in the variable.\nIf we have two many bins then we see a jagged pattern caused by random variation rather than the true shape of the distribution.\n\nCompare these three histograms with different numbers of bins:\n\n\n\n\n\n\nThe middle histogram shows us that while humans (and similar-sized creatures) are predominant even a long time ago in galaxies far, far away, there is also a clump of shorter creatures with heights below 100cm.\nHowever, that shape is obscured in the plot on the left with just three bins. With too few bins, we destroy any fine grained shape in the distribution.\nIt is equally hard to see the overall shape in the right-hand histogram, because there are so many bins that our eyes are distracted by the sharp transitions between neighboring bins. However, these patterns are caused by random variation, i.e. by accidentally having a few more Star Wars characters in one bin."
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#one-categorical-variable-bar-charts",
    "href": "src/book/05_visualization_chapter.html#one-categorical-variable-bar-charts",
    "title": "5  Visualizing Data",
    "section": "5.4 One categorical variable: bar charts",
    "text": "5.4 One categorical variable: bar charts\n\nWe can also visualize the distribution of a categorical variable. We gain use a graph with bars, but whereas in a histogram we had to divide the x-axis into bins, we now have existing categories in the variable.\nWe can visualize the distribution by showing the number of values in each category (the frequency of each category).\nTo see how, let’s pick the sex variable from the starwars dataframe. Here’s what the first few rows looked like:\n\n\n\n\n\nname\nsex\n\n\n\n\nLuke Skywalker\nmale\n\n\nC-3PO\nnone\n\n\nR2-D2\nnone\n\n\nDarth Vader\nmale\n\n\nLeia Organa\nfemale\n\n\nOwen Lars\nmale\n\n\n\n\n\nThe first thing we need to do is count the number of values of each sex in the sex column. We can do this with the table() function:\n\ntable(starwars$sex)\n\n\n        female hermaphroditic           male           none \n            16              1             60              6 \n\n\nWe can then use the barplot() function to make a bar graph of those frequencies:\n\nh &lt;- table(starwars$sex)\nbarplot(h)\n\n\n\n\nNote that saving the table to a variable (which we have called h) is optional - we could instead nest the table() function inside the barplot() function like this:\nbarplot(table(starwars$sex))\n\n\n\n\n\n\nTip\n\n\n\n\n\n5.4.1 Nesting vs sequential functions\nWhen should you nest functions and when should you run them sequentially?\nIn general, nested functions can be harder to read. It’s fine if you only have two or three, but nesting more than that results in a lot of parentheses and arguments that are hard to sort out.\nWe can instead run each function one at a time, and save the output in a new variable. However, if we only want to use that variable once (in the next function), then we end up creating a lot of variables that we don’t really need.\nIn the next chapter we will learn about a new operator (called a pipe) that will allow us to run functions sequentially and avoid creating lots of intermediate variables."
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#two-variables-scatter-plots",
    "href": "src/book/05_visualization_chapter.html#two-variables-scatter-plots",
    "title": "5  Visualizing Data",
    "section": "5.5 Two variables: scatter plots",
    "text": "5.5 Two variables: scatter plots\nWhen we have two or more variables, we often want to see how these variables covary, i.e. how does the distribution of one variable differ at different values of another variable.\nIf we have two continuous variables, then we usually visualize their covariation with a scatter plot. You have probably seen graphs like tis before, in which we draw dots at meeting points of \\(x\\) and \\(y\\) values.\nIn R, we can create simple scatter plots with the plot() function, such as this graph of mass vs. weight of Star Wars characters:\n\nplot(x = starwars$height, y = starwars$mass)\n\n\n\n\n\nNote the two parameters that we pass arguments to, x and y, for the columns of data that we want to plot on the x and y axes respectively.\nWhen we talk about a scatter plot of “A vs. B”, by convention A is the variable that we are plotting on the y-axis. I.e. we would say that the graph above shows “mass vs height”, not “height vs. mass”.\nA final convention is that the x-axis contains the variable which we think probably explains the other one. I.e. I think it makes sense to think as height causing changes in mass, not mass causing changing in height, since an increase in height tends to make you weigh more. However, as middle age has taught me, an increase in mass does not necessarily lead to a change in height…"
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#trends-line-graphs",
    "href": "src/book/05_visualization_chapter.html#trends-line-graphs",
    "title": "5  Visualizing Data",
    "section": "5.6 Trends: line graphs",
    "text": "5.6 Trends: line graphs\nAnother type of graph that you may encounter for two continuous variables is the line graph.\nHowever, it is important to note that a line graph is not appropriate for many datasets.\nHere’s why. When we connect points with a line, we are implying that there is some connection between those points. Typically we connect points in the direction of the x-axis, going from left to right. By drawing a line between, for example, the points (1,1) and (2,3) we are implying that a particular thing had the y-axis attribute equal to 1 when x=1, and then when \\(x=2\\) that same thing had changed its y-axis attribute to a value of 3.\nIn other words, we should only draw a line graph to connect points if those points represent sequential observations of the same thing. A line graph shows us changes in values, whereas a scatter plot typically shows independently observed values of the same thing.\nIn would be bad, for example, to use a line graph to show the mass vs. height of Star Wars characters, because there is no reason to connect the point for Jabba the Hutt to the point for C-3PO1. These rows in the dataset are completely separate things, not two observations of the same thing. If we compare such a line graph to the previous scatter plot that we made, we can clearly see that the line graph looks awful:\n\n\n\n\n\nWe typically use line plots when we are measuring something repeated over time. Time is then the sequential value on the x-axis (because time in graphs always goes from left to right). A dataset that contains repeated observations of the same thing over time is called a time series.\nFor example, here is a scatter plot and a line graph showing the body temperature of a beaver over time. All the body temperature measurements are from the same beaver, so this is a time series and it makes sense to connect the points. In fact, it is actually easier to understand the line graph than a scatter plot of the same data, because it is hard for our brain to mentally draw the connecting lines in the scatter plot.\n\nbeaver_1_plus &lt;- beaver1 %&gt;%\n  mutate(\n    hour = time %/% 100,\n    minutes = time %% 100,\n    day_and_time = ddays(day-346) + dhours(hour) + dminutes(minutes)\n  )\npar(mfrow = c(1, 2))\nplot(\n  beaver_1_plus$day_and_time, \n  beaver_1_plus$temp, \n  xlab = \"Time (seconds)\", \n  ylab = \"Body temperature (Celsius)\"\n  )\nplot(\n  beaver_1_plus$day_and_time, \n  beaver_1_plus$temp, \n  xlab = \"Time (seconds)\", \n  ylab = \"Body temperature (Celsius)\", \n  type = \"l\"\n  )\n\n\n\npar(mfrow = c(1, 1)) # Back to the original graphics device\n\nWe can create a line graph using the plot() function with the additional argument type = \"l\", for example:\nplot(x = column_1, y = column_2, type = \"l\")\nWe supply the character \"l\" to the type parameter to indicate that we want lines in this graph."
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#sec-visualization-best-practices",
    "href": "src/book/05_visualization_chapter.html#sec-visualization-best-practices",
    "title": "5  Visualizing Data",
    "section": "5.7 Best practices for graphs",
    "text": "5.7 Best practices for graphs\nTODO: show some good and bad graphs to illustrate these points.\n\nCommunicate as much information as possible with as little ink as possible\n\n\nWhite space is good\nExcessive use of color is bad.\nFun and artistic infographics often obscure the actual data.\n\n\nCreate graphs that meet the expectations of the viewer, and be explicit when you do something different.\n\n\nAxis ranges (start at 0, or be clear if not. Don’t start elsewhere to exaggerate a small difference.)\nDirection of data on axis. (left to right, and bottom to top)\nTime on x-axis\nScales on subplots\n\n\nMake comparisons easy.\n\n\nLengths, not areas.\nSide-by-side comparisons - don’t make people move things mentally to see how they are different.\n\n\nLabel your graphs.\nAvoid 3D graphs like the plague."
  },
  {
    "objectID": "src/book/05_visualization_chapter.html#footnotes",
    "href": "src/book/05_visualization_chapter.html#footnotes",
    "title": "5  Visualizing Data",
    "section": "",
    "text": "Nobody suggest this to JJ Abrams…↩︎"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#wrangling-overview",
    "href": "src/book/06_wrangling_chapter.html#wrangling-overview",
    "title": "6  Wrangling Data",
    "section": "6.1 Wrangling overview",
    "text": "6.1 Wrangling overview\n\n\nSlides: PDF"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#the-dplyr-package-and-the-tidverse",
    "href": "src/book/06_wrangling_chapter.html#the-dplyr-package-and-the-tidverse",
    "title": "6  Wrangling Data",
    "section": "6.2 The dplyr package and the tidverse",
    "text": "6.2 The dplyr package and the tidverse\n\nTBA: packages and loading with library()"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#the-presidential-dataset",
    "href": "src/book/06_wrangling_chapter.html#the-presidential-dataset",
    "title": "6  Wrangling Data",
    "section": "6.3 The presidential Dataset",
    "text": "6.3 The presidential Dataset\n\n6.3.1 Examining the data\n\nFor the first part of this chapter we will be using a dataset of US presidents. This dataset is stored in a variable called presidential.\n\n\n\nUse head() function to check some of the contents of the presidential dataframe. (The head() function prints the first six rows of a dataframe.)\nRun head(presidential) in the R Console and examine the output."
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#picking-columns-with-select",
    "href": "src/book/06_wrangling_chapter.html#picking-columns-with-select",
    "title": "6  Wrangling Data",
    "section": "6.4 Picking columns with select()",
    "text": "6.4 Picking columns with select()\n\n6.4.1 The select function\nThe select() function can be used to pick certain columns of a dataset. The output of select() is a new dataframe containing just the columns that you specified.\nIgnore the video’s instruction to follow along in RStudio: you will try this function out on the next page of this tutorial instead.\n\n\nSlides: PDF\n\n\n6.4.2 A simple select()\n\n\n\nExercise TBM\n\n\n\n\n\n# Replace the blank with the name of the column\nselect(presidential, _____)\n\n\nselect(presidential, name)\n\n\ngrade_code(\"Nice work!\")\n\n\n\n\n6.4.3 Selecting multiple columns\nWe can put as many column names as we want into the select function, separating each by a comma.\n\n\n\nExercise TBM\n\n\n\n\n\n\n\n6.4.4 Selecting a range\nIn R, the range operator, : (the colon punctuation symbol) indicates a range.\nFor example, this code create a vector of all the integer numbers in the range of 1-10:\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n(We could also have written c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) as you learned in the first week, but the range operator is a convenient shorthand in this scenario.)\nWe can also use the range operator to indicate a range of columns inside dplyr functions such as select:\nselect(presidential, name:end)\nThis selects all sequential columns from name to end (which in this case is name, start, and end).\n\n\n\nExercise TBM\n\n\n\n\n\n\nNote:\nYou combine ranges and individual column selections by separating them by commas, e.g.\nselect(presidential, name:start, party)"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#sorting-with-arrange",
    "href": "src/book/06_wrangling_chapter.html#sorting-with-arrange",
    "title": "6  Wrangling Data",
    "section": "6.5 Sorting with arrange()",
    "text": "6.5 Sorting with arrange()\n\n6.5.1 The arrange function\n\n\nSlides: PDF\n\n\n6.5.2 Arrange practice\n\n\n\nExercise TBM"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#piping-data-between-functions",
    "href": "src/book/06_wrangling_chapter.html#piping-data-between-functions",
    "title": "6  Wrangling Data",
    "section": "6.6 Piping data between functions",
    "text": "6.6 Piping data between functions\n\n6.6.1 The pipe %&gt;% operator\n\n\nSlides: PDF\nAs described in the video, the pipe operator takes the value on its left and inserts it as the first argument of the function on the right.\nIn other words:\nsome_data %&gt;% someFunction()\nis equivalent to:\nsomeFunction(some_data)\nIf there are other arguments supplied to the function, they get “pushed back” so that the data piped in can claim the “first argument” spot:\nsome_dataframe %&gt;% someFunction(this_is_really_argument_2)\nis the same as:\nsomeFunction(some_data, this_is_really_argument_2)\n\n\n6.6.2 Piping practice\n\n\n\nExercise TBM\n\n\n\n\n(Note that we can put a new line after the %&gt;% operator as above - R knows that there must be a right-hand side, so it treats both lines as the same line.)\n\nWhy does this matter?\nThe first argument of functions in the tidyverse is the dataframe. However, many functions also output a dataframe (as does a variable holding a dataframe, such as presidential). So we can just pipe from one function to another and build up a long chain of functions: i.e. a pipe:\nsome_dataframe %&gt;%\n  select(some_columns) %&gt;%\n  some_other_function() %&gt;%\n  a_third_function(different_argument)\n\nNote that I have invented some made-up functions and variable names in the code above - this is called pseudocode."
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#boolean-logic",
    "href": "src/book/06_wrangling_chapter.html#boolean-logic",
    "title": "6  Wrangling Data",
    "section": "6.7 Boolean logic",
    "text": "6.7 Boolean logic\n\n6.7.1 Review of Boolean logic\n\n\nSlides: PDF\n\n\n6.7.2 Boolean logic quiz\nYou are already a little familiar with Boolean operators from the Introduction to R tutorial, so let’s refresh our memories with a quick quiz.\n\n\n\nQuiz TBA"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#picking-rows-with-filter",
    "href": "src/book/06_wrangling_chapter.html#picking-rows-with-filter",
    "title": "6  Wrangling Data",
    "section": "6.8 Picking rows with filter()",
    "text": "6.8 Picking rows with filter()\n\n6.8.1 The filter function\n\n\nSlides: PDF\n\n\n6.8.2 Some practice\n\n\n\nExercise TBM\n\n\n\n\n\n\n6.8.3 Filtering with multiple conditions\n\n\n\nExercise TBM"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#creating-columns-with-mutate",
    "href": "src/book/06_wrangling_chapter.html#creating-columns-with-mutate",
    "title": "6  Wrangling Data",
    "section": "6.9 Creating columns with mutate()",
    "text": "6.9 Creating columns with mutate()\n\n6.9.1 The mutate function\n\n\nSlides: PDF\n\n\n6.9.2 End year\n\n\n\nExercise TBM"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#sec-wrangling-groupby-summarize",
    "href": "src/book/06_wrangling_chapter.html#sec-wrangling-groupby-summarize",
    "title": "6  Wrangling Data",
    "section": "6.10 Grouping and summarizing",
    "text": "6.10 Grouping and summarizing\n\n6.10.1 The group_by and summarize functions\n\n\nSlides: PDF\n\n\n6.10.2 Practice\n\n\n\nExercise TBM"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#what-is-tidy-data",
    "href": "src/book/06_wrangling_chapter.html#what-is-tidy-data",
    "title": "6  Wrangling Data",
    "section": "6.11 What is tidy data?",
    "text": "6.11 What is tidy data?\nSo far we have looked at relatively simple data wrangling operations that return subsets of the data. However, we often want to reshape the dataframe to turn it into a format called tidy data. This video will introduce you to what tidy data looks like."
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#converting-columns-to-rows",
    "href": "src/book/06_wrangling_chapter.html#converting-columns-to-rows",
    "title": "6  Wrangling Data",
    "section": "6.12 Converting columns to rows",
    "text": "6.12 Converting columns to rows\n\n6.12.1 The pivot_longer() function\n\n\n\n\n\n\n6.12.2 Practice\nLet’s try the pivot_longer() function on the presidential dataset. We will reshape this dataset to convert the two data columns (start and end) into rows, with a names column that indicates the name of the original column, and a values column that holds the dates.\nIn other words, we want to convert the presidential dataframe:\n\n\n\nname\nstart\nend\nparty\n\n\n\n\nEisenhower\n1953-01-20\n1961-01-20\nRepublican\n\n\nKennedy\n1961-01-20\n1963-11-22\nDemocratic\n\n\n…\n…\n…\n…\n\n\n\ninto this:\n\n\n\nname\ntype_of_date\ndate\nparty\n\n\n\n\nEisenhower\nstart\n1953-01-20\nRepublican\n\n\nEisenhower\nend\n1961-01-20\nRepublican\n\n\nKennedy\nstart\n1961-01-20\nDemocratic\n\n\nKennedy\nend\n1963-11-22\nDemocratic\n\n\n…\n…\n…\n…\n\n\n\nThe data in both dataframes is the same, but we have changed the shape of the dataframe by converting columns into rows.\n\n\n\nExercise TBM"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#turning-rows-to-columns",
    "href": "src/book/06_wrangling_chapter.html#turning-rows-to-columns",
    "title": "6  Wrangling Data",
    "section": "6.13 Turning rows to columns",
    "text": "6.13 Turning rows to columns\n\n6.13.1 The pivot_wider() function\n\n\n\n\n\n\n6.13.2 Practice\nLet’s use the pivot_wider() function to undo the transformation we did earlier with the pivot_longer() function.\nI.e. we want to turn this:\n\n\n\nname\ntype_of_date\ndate\nparty\n\n\n\n\nEisenhower\nstart\n1953-01-20\nRepublican\n\n\nEisenhower\nend\n1961-01-20\nRepublican\n\n\nKennedy\nstart\n1961-01-20\nDemocratic\n\n\nKennedy\nend\n1963-11-22\nDemocratic\n\n\n…\n…\n…\n…\n\n\n\nback into this:\n\n\n\nname\nstart\nend\nparty\n\n\n\n\nEisenhower\n1953-01-20\n1961-01-20\nRepublican\n\n\nKennedy\n1961-01-20\n1963-11-22\nDemocratic\n\n\n…\n…\n…\n…\n\n\n\n\n\n\nExercise TBM\n\n\n\n\n\n\n\n6.13.3 What happened to those dates?\nWhen we tried to reverse the transformation, we were not able to retrieve the start and end date columns back in the same format as we originally started with in the presidential dataframe.\nInstead of actual dates in the column, you should see values such as &lt;date [1]&gt;. This indicate that each cell of the table holds a list of dates instead of just a single date.\nYou code will also have generated a warning about this: Warning: Values are not uniquely identified; output will contain list-cols.\nWhat are these non-unique values that we are being warned about? If you look through the table created by pivot_wider(), you will notice that one president’s date list is longer than the others (see if you can find which president this is).\n\nIn fact, there were two US presidents with this same surname during the period of this dataset, and consequently, when we tried to widen the table and identify unique rows, we identified 2 start dates and 2 end dates for this presidential surname.\nTo avoid these problems when using pivot_wider(), we always need at least one column in the remaining non-widened columns that is unique for each row we wish to generate in our output. Here we fail that requirement, because one of the presidential surnames in our dataset is used by two seperate observations (presidents).\nBy default, pivot_wider() assumes that all remaining columns are unique for all widened rows. However, if there are only one or a few unique columns, these can be specified by supplying those column names to the id_cols argument of the pivot_wider() function."
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#splitting-and-combining",
    "href": "src/book/06_wrangling_chapter.html#splitting-and-combining",
    "title": "6  Wrangling Data",
    "section": "6.14 Splitting and combining",
    "text": "6.14 Splitting and combining\n\n6.14.1 The separate function\n\n\nSlides: PDF\n\n\n\n6.14.2 The unite function\n\n\nSlides: PDF\nThat’s it for this tutorial!"
  },
  {
    "objectID": "src/book/06_wrangling_chapter.html#other-data-wrangling-functions",
    "href": "src/book/06_wrangling_chapter.html#other-data-wrangling-functions",
    "title": "6  Wrangling Data",
    "section": "6.15 Other data wrangling functions",
    "text": "6.15 Other data wrangling functions\n\n6.15.1 Other helpful dplyr verbs\n\n\nSlides: PDF"
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#from-plot-to-ggplot-...",
    "href": "src/book/07_ggplot_chapter.html#from-plot-to-ggplot-...",
    "title": "7  Graphs with ggplot",
    "section": "7.1 From plot() to ggplot() + ...",
    "text": "7.1 From plot() to ggplot() + ...\nSo far we have created graphs with base R1 functions like plot() and hist().\nHowever the graphs created via these functions are not very visually appealing. It also becomes difficult to create more complex graphs, and the ways to do so are not very intuitive.\nIn this chapter we will learn how to use alternative graphing functions from the ggplot2 package. This is a core part of the tidyverse, just like the dplyr and tidyr packages that we learned about for data wrangling.\nFor example, instead of using hist() to create a histogram:\n\nhist(x = starwars$height, breaks = 10, data = starwars)\n\n\n\n\n…we will use an alternative pair of functions, ggplot() and geom_histogram(), like this:\n\nggplot(data = starwars) +\n  geom_histogram(\n    mapping = aes(x = height),\n    bins = 10\n  )\n\n\n\n\nAs you can see, the histograms are very similar the same. However, we’ve avoided this way of creating graphs up until now, because we’ve been trying to keep our code as simple as possible.\nNow we need to make the trade of slightly more complicated code in exchange for much better graphs. So let’s jump in and see how and why this works."
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#sec-ggplot-histogram-layer",
    "href": "src/book/07_ggplot_chapter.html#sec-ggplot-histogram-layer",
    "title": "7  Graphs with ggplot",
    "section": "7.2 Graphs as layers and transformations",
    "text": "7.2 Graphs as layers and transformations\nThe ggplot2 package gets its name because it’s based on a concept called the Grammar of Graphics (hence ggplot…). This is a fascinating topic that we will learn more about later in this book, but the key idea is that all data visualizations can be described using a common set of terms and ideas (i.e. a “grammar”). The terms of this grammar correspond to the functions and their parameters in the ggplot2 package.\nOne of the most important parts of this grammar are the layers that we can add to a graph.\nFor example, the ggplot() function by itself just creates a blank canvas, i.e. the base layer of the graph:\n\nggplot(data = starwars)\n\n\n\n\nWe can then add layers (created by other functions) by combining them with the + operator.\nTo get some kind of graph layer we need to take the data and map it to a geometric shape.\nFor example, if we wanted to map the height column of the starwars dataset to the geometric shape of a histogram’s bars, we could use this code:\ngeom_histogram(mapping = aes(x = height))\nA few things to note:\n\nThe geom_histogram() function is an example of what we call a geom function (each geom function specifies a different type of geometric shape).\nGeom functions have a parameter called mapping which tells R how to convert a column of data into a layer.\nThe argument that we pass to the mapping parameter is a function called aes() (this is short for “aesthetic”). Inside the aes() function we need to specify any parts of the histogram’s appearance that are determined by a column in the dataset.\n\nIn our example the x-axis of the histogram needs to show the height variable.\n\n\nWe then add this layer to the canvas created by ggplot() with the addition operator, +.\nAnd so our final code looks like this:\nggplot(data = starwars) +\n  geom_histogram(mapping = aes(x = height))\n\nggplot(data = starwars) +\n  geom_histogram(\n    mapping = aes(x = height),\n    bins = 30\n  )"
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#aesthetic-mappings-and-other-parameters",
    "href": "src/book/07_ggplot_chapter.html#aesthetic-mappings-and-other-parameters",
    "title": "7  Graphs with ggplot",
    "section": "7.3 Aesthetic mappings and other parameters",
    "text": "7.3 Aesthetic mappings and other parameters\nWe refer to this combination of the mapping parameter and its aes() argument as an aesthetic mapping, which is a fancy way of saying how we convert columns of the dataset into some visual representation.\nBut not every part of a graph is determined by data in the dataset. For example, there is no column in the starwars dataset that tells us how many bins this histogram should have. Instead we need to specify that number ourselves, with another piece of data (i.e. the number of bins).\nSince this number is not in the dataset, it is not an aesthetic mapping. Therefore we specify the number of bins as an argument of the geom_histogram() function, and not of the aes() function, like so:\n\nggplot(data = starwars) +\n  geom_histogram(\n    mapping = aes(x = height),\n    bins = 30\n  )\n\n\n\n\nDo you see how the geom_histogram() function has two parameters, mapping and bins, whereas the aes() function has a single parameter (x)?"
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#sec-ggplot-scatter-plots",
    "href": "src/book/07_ggplot_chapter.html#sec-ggplot-scatter-plots",
    "title": "7  Graphs with ggplot",
    "section": "7.4 Scatter plots with ggplot()",
    "text": "7.4 Scatter plots with ggplot()\nHopefully you are beginning to see that the ggplot() syntax uses many of the same parameters as qplot(), just in different places.\nWe can create a scatter plot by switching to a geom function called geom_point() and passing an additional column to the aes() function to go on the y axis:\n\nggplot(data = starwars) +\n  geom_point(\n    mapping = aes(x = height, y = mass)\n  )"
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#color-and-fill",
    "href": "src/book/07_ggplot_chapter.html#color-and-fill",
    "title": "7  Graphs with ggplot",
    "section": "7.5 Color and fill",
    "text": "7.5 Color and fill\nSometimes we wish to highlight different categories of data in a graph. There are different ways that qwe could do this, but a common solution is to use color.\nFor example, let’s say that we want to investigate the relationship between mass versus height again, but also look at how it varies between genders.\nThe starwars dataframe conveniently contains a categorical gender column that tells us this information:\n\nstarwars |&gt;\n  select(name, mass, height, gender) |&gt;\n  head()\n\n# A tibble: 6 × 4\n  name            mass height gender   \n  &lt;chr&gt;          &lt;dbl&gt;  &lt;int&gt; &lt;chr&gt;    \n1 Luke Skywalker    77    172 masculine\n2 C-3PO             75    167 masculine\n3 R2-D2             32     96 masculine\n4 Darth Vader      136    202 masculine\n5 Leia Organa       49    150 feminine \n6 Owen Lars        120    178 masculine\n\n\nWe can add an additional aesthetic mapping to our scatter plot from the previous section, which will map the gender column to the color aesthetic of the scatter point layer:\n\nggplot(data = starwars) +\n  geom_point(\n    mapping = aes(x = height, y = mass, color = gender)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilarly we can also color histograms - however the color parameter colors the outside of shapes:\n\nggplot(data = starwars) +\n  geom_histogram(mapping = aes(x = height, color = gender))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nThis graph is hard to interpret. It would be easier if we could color inside the shapes - fortunately we can do this using the fill parameter instead of color:\n\nggplot(data = starwars) +\n  geom_histogram(mapping = aes(x = height, fill = gender))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nNote that this still goes inside the aes() function, because we are still mapping the gender column, just now to the fill aesthetic.\nOne other thing to note is that, by default, ggplot2 will stack bars of different colors on top of each other. However, this makes it hard to compare the relative heights of the bars, in direct contravention of the graphing guidelines that we learned in Section 5.7.\nThus what we need to do is to change the position of the bars so that each bin’s bars overlap. We will also need to make them transparent so that we can see through to the bars behind. We can do this with the position and alpha parameters:\n\nggplot(data = starwars) +\n  geom_histogram(\n    mapping = aes(x = height, fill = gender),\n    position = \"identity\",\n    alpha = 0.4\n    )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nA few things to note:\n\nWe set position = \"identity\" to cause the bars to all start at the x-axis.\nWe set alpha = 0.4 to make the bars 40% transparent. You can set alpha anywhere from 1 (completely opaque) to 0 (completely transparent, i.e. invisible). Usually a value between 0.2-0.4 works well.\nBoth \"identity\" and 0.4 are values, not columns of the dataframe, so we need to supply these two new parameters to the geom function instead of the aes() function (i.e. we are not creating any aesthetic mapping to the data in starwars with these settings).\n\nIt is actually getting a little hard to interpret some of the overlapping bars in the plot above, because when too many colors overlap we get an indistinguishable grey mess. Coloring histograms woks best when we have only two (or maybe three) categories. More categories than that and we need to start considering whether a different type of graph might communicate the patterns in the data more clearly."
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#piping-to-ggplot",
    "href": "src/book/07_ggplot_chapter.html#piping-to-ggplot",
    "title": "7  Graphs with ggplot",
    "section": "7.6 Piping to ggplot()",
    "text": "7.6 Piping to ggplot()\nOne advantage of ggplot() over plot() is that we can pipe a dataframe to ggplot() because the first parameter of ggplot() is the dataset to be used.\nSo instead of explicitly passing the starwars dataframe to the data parameter:\nggplot(data = starwars) + ...\n…we could write this:\nstarwars %&gt;%\n  ggplot() + ...\nThis might not seem like much, but it does mean that we can put the graphing functions at the end of a series of piped functions that transform and wrangle our dataset, for example:\nsome_dataset %&gt;%\n  mutate(...) %&gt;%\n  filter(...) %&gt;%\n  ggplot() + geom_FUNCTION(...)\nNote how we use pipes to connect a series of sequential data wrangling steps leading up to ggplot(), but then after ggplot() we have to switch to the + operator because we are then adding layers together. Don’t try to pipe the output of ggplot() on to a geom function because it won’t work (because we are trying to combine things in the graph, not work on the output of the previous function)."
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#labeling-graphs",
    "href": "src/book/07_ggplot_chapter.html#labeling-graphs",
    "title": "7  Graphs with ggplot",
    "section": "7.7 Labeling graphs",
    "text": "7.7 Labeling graphs\nTODO: This was moved from EDA and needs updating to be consistent with chapter\nIt is good practice to label all the graphs we create. We can do this by adding the labs() function to a graph:\n\nstarwars %&gt;%\n  ggplot() +\n  geom_point(\n    mapping = aes(x = height, y = mass)\n  ) +\n  labs(\n    title = \"Mass vs. height of Star Wars characters\", \n    y = \"mass (kg)\", \n    x = \"height (cm)\"\n    )\n\nWarning: Removed 28 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNotice how:\n\nthe labs() function is a separate function that we add on to the graph as a separate layer with the + operator\ninside the labs() function, we can supply an argument to the title parameter to change the title, and the y and x arguments to change the labels on those axes.\n\nA good title should succinctly describe what is being plotted on the graph.\nAxis labels should indicate what the variable is, and what units it is measured in.\n\n\nWe can also update any legend label as well by providing the same parameter name that we used in the aes() function. For example, with fill:\n\nggplot(data = starwars) +\n  geom_histogram(\n    mapping = aes(x = height, fill = gender),\n    position = \"identity\",\n    alpha = 0.4\n    ) +\n  labs(\n    title = \"Histogram of heights of Star Wars characters\",\n    x = \"height (cm)\",\n    fill = \"Gender of character\"\n  )\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\nNote that I have left the default count label on the y-axis of this histogram, since that is a perfectly adequate name and has no units.\nIn the title I have explicitly called out that this is a histogram, since there are other types of graphs that also use bars and so we can make it clear to any viewer what is going on here. (There was no need to do anything similar in the previous scatter plot, since it was clearly a scatter plot an is unlikely to be confused with a different type of graph.)\n\n\nTODO: book exercises\n\n\n\nUsing the labs() function, add a title and y-axis label to the boxplot of price that you created earlier (we will leave the x-axis label as its default, since that is adequate for this graph.)"
  },
  {
    "objectID": "src/book/07_ggplot_chapter.html#footnotes",
    "href": "src/book/07_ggplot_chapter.html#footnotes",
    "title": "7  Graphs with ggplot",
    "section": "",
    "text": "I.e. functions that come as part of R, and don’t need to be imported from an extra package.↩︎"
  },
  {
    "objectID": "src/book/09_computing_chapter.html#welcome",
    "href": "src/book/09_computing_chapter.html#welcome",
    "title": "8  More about R",
    "section": "8.1 Welcome",
    "text": "8.1 Welcome\nThis chapter/tutorial will start with a refresher on basic programming in R (from Module 1: variables, data types, functions), and then introduce some additional programming concepts such as control flow and loops."
  },
  {
    "objectID": "src/book/09_computing_chapter.html#values-and-variables",
    "href": "src/book/09_computing_chapter.html#values-and-variables",
    "title": "8  More about R",
    "section": "8.2 Values and variables",
    "text": "8.2 Values and variables\n\n8.2.1 A recap\nBy now you are familiar with the idea that in R we have values and variables. We can write something like:\nx &lt;- 2\nto store the value 2 in the variable x. We do so using the assignment operator, &lt;-.\nThis allows us to use a variable such as x in future lines of code. When that future code is run, the variable will be replaced with its value, e.g.\nx + 3\nbecomes\n2 + 3\n\n\n8.2.2 Expressions and statements\nAs we learn more about programming, it’s useful to distinguish between different types of code.\nIn programming, an expression is a piece of code that returns a value. For example:\n\n2 + 2 returns the value 4\n1 == 2 returns the value FALSE\n\nIf you run a line of R code that contains just an expression by itself, the expression will be evaluated, and the result will by displayed in the RStudio Console.\nHowever, the result of an expression is not saved by default. Instead it is just calculated and then discarded by the program. Otherwise, if you kept bits of data you don’t need, your computer would very quickly run out of memory!\nTherefore we almost never want an expression by itself - instead we want to do something with it, such as assigning it to a variable. Later in this tutorial we will learn of other things we can do with the results of expressions.\nA statement is a line of code that runs but does not return a value. If nothing is printed out in the Console when you run a line of code, then that line is a statement.\n\n\n8.2.3 How an R program runs\nWhat happens when you run an R program (or a code chunk in an RMarkdown document)? And why does this mean that 2 + by itself is not a valid expression?\nBut why will this code cause an error:\n2 +\nwhen this code will run successfully?\n2 +\n2\nWhen you run an R program, your code is sent, line by line to another program called the R interpreter (this is what is running in the RStudio Console). The interpreter converts your code into electrical signals that can be understood by your computer, and then takes the computer’s output and turns it back into a readable response that it displays on the screen.\nWe do not need to worry about how this happens, but the important thing to note is that this happens one line at a time. So this is why 2 + doesn’t work: it gets to the end of the line and has nothing to add to the first number.\nHowever… if a line ends in an incomplete expression, then before giving an error, R will first look to see if the next line could be the continuation of the first. This is why this code chunk works, even though the expression has been broken over multiple lines:\n2 +\n2\nAs programmers, we want to format our code to be read by humans not computers (R only cares if your code is correct, not it is easy to read). It sometimes helps readability to break long lines into multiple lines. For example, compare:\nsome_dataframe %&gt;% filter(col1==2) %&gt;% select(col2,col3) %&gt;% ggplot()+geom_point(mapping=aes(x=col3,y=col2))\nwith the same code broken over several lines:\nsome_dataframe %&gt;%\n  filter(col1 == 2) %&gt;% \n  select(col2, col3) %&gt;% \n  ggplot() + \n  geom_point(\n    mapping = aes(\n        x = col3,\n        y = col2\n      )\n    )\nAlso note that indentation aids readability by indicating what goes together:\n\nWhen we break an expression over multiple lines, you should indent every subsequent line of that expression by 2 spaces to indicate to a reader that it is part of the same expression.\nIn addition, if you insert a line break between a set of parentheses (...), you should also indent the contents of those parentheses by 2 spaces (as we have done with both the geom_point() and aes() functions above).\n\nLong lines of code in an RMarkdown code chunk will also overrun the right margin of a PDF after you knit, as lines in a code chunk are not automatically wrapped onto the next line, unlike regular text. Therefore you may have to break up a long line simply to fit it on the page.\nWhat about this code?\n2 + \n  y &lt;- TRUE\nWhat about this code chunk?\nsome_dataset %&gt;%\n  filter(col_A == \"some_value\")\n  mutate(\n    new_column = col_B * 100\n  )"
  },
  {
    "objectID": "src/book/09_computing_chapter.html#data-types",
    "href": "src/book/09_computing_chapter.html#data-types",
    "title": "8  More about R",
    "section": "8.3 Data types",
    "text": "8.3 Data types\n\nIn the first interactive tutorial, An Introduction to Programming in R, you learned about basic data types such as numbers, character strings, and Boolean values.\nYou also learned about more complex data structures such as vectors and lists which can hold multiple values of those basic data types.\nIf you do not remember this, go back to the first interactive tutorial to refresh your memory.\nWe also have data structures that can hold a 2-dimensional table of data (with rows and columns): the dataframe.\nHowever, the dataframe has been in R since the language was first created, and as a result it has some odd behaviours that are counterintuitive and can lead to bugs.\nThe tidyverse collection of packages that we have been using add a new version of a dataframe that fix a lot of these problems called the tibble. We will use the names dataframe and tibble interchangeably in this course, and for the most part they are pretty similar, but you should be aware that they have some subtle differences and you should use tibbles when possible.\n\n8.3.1 Vectors\nYou can create a vector with the c() function. You can also create a vector of numbers using the : operator. For example, these two lines both create the same vector of the values 1 through 5:\n\nc(1,2,3,4,5)\n\n[1] 1 2 3 4 5\n\n\n\n1:5\n\n[1] 1 2 3 4 5\n\n\n\nCreate a vector of all the integer numbers from 2 to 250.\n\n\n# hint text\n\"Try using the `:` operator\"\n\n\n2:250\n\n\n# check code\ngradethis::grade_code()\n\n\n\n8.3.2 Other vector tips\nThere are several other useful things to remember about vectors:\n\nYou can combine two vectors into a single vector with the c() function:\n::: {.cell hash=‘09_computing_chapter_cache/html/unnamed-chunk-3_b28dd3c71a72bf7ddcae7525b0898aee’}\nx &lt;- 1:3\ny &lt;- 4:6\n\nc(y, x)\n::: {.cell-output .cell-output-stdout} [1] 4 5 6 1 2 3 ::: :::\nYou can extract a single value from a vector by indexing into the vector with square brackets [...] and the position of item that you want:\n::: {.cell hash=‘09_computing_chapter_cache/html/unnamed-chunk-4_badc71404c226d65b9f148670354c252’}\nx &lt;- 101:110\n\nx[5]\n::: {.cell-output .cell-output-stdout} [1] 105 ::: :::\nYou can change any value in a vector with square brackets and the assignment operator:\n::: {.cell hash=‘09_computing_chapter_cache/html/unnamed-chunk-5_11eedf83ab32e12f0c357bfc6edfe0e4’}\nx &lt;- 1:5\nx[2] &lt;- 42\n\nx\n::: {.cell-output .cell-output-stdout} [1]  1 42  3  4  5 ::: :::\nYou can even extend a vector by one element by assigning to a position 1 higher than it’s current length:\n::: {.cell hash=‘09_computing_chapter_cache/html/unnamed-chunk-6_f19293e9c03d2b1ed6d0c1cbac149fff’}\nx &lt;- 1:5\nx[6] &lt;- 42\n\nx\n::: {.cell-output .cell-output-stdout} [1]  1  2  3  4  5 42 ::: :::\n\n\n\n\n8.3.3 Combining different data into lists\nTODO: section moved from first R chapter - needs rewriting\nSo far we have looked at pieces of data by themselves:\n\na &lt;- 1\nb &lt;- \"Hello!\"\nc &lt;- TRUE\nprint(a)\n\n[1] 1\n\nprint(b)\n\n[1] \"Hello!\"\n\nprint(c)\n\n[1] TRUE\n\n\nBut what about if we want to combine multiple pieces of data together?\nR includes several types of container that can hold multiple pieces of data. We can then refer to that container by a single variable. For example, instead of the three variables above, we can create a list object that holds all three values:\n\nl &lt;- list(1, \"Hello!\", TRUE)\nl\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"Hello!\"\n\n[[3]]\n[1] TRUE\n\n\nWe create a list using list(). Every value in the list goes inside the parentheses, separated by commas.\n\n\n\nCreate a list holding 4 values (in this order): 10, “z”, FALSE, -0.1*10\n\n\n\n\n\nlist(10, \"z\", FALSE, -0.1*10)\n\n\n\n\n8.3.4 Tibbles\nYou can create a tibble using the tibble() function. The arguments of the function should be vectors that will form the columns of the table, for example:\n\nb &lt;- c(TRUE, FALSE, TRUE)\nz &lt;- c(\"Anna\", \"Bob\", \"Carlos\")\n\ntibble(\n  a = 1:3,\n  4:6,\n  student_name = z,\n  b\n)\n\n# A tibble: 3 × 4\n      a `4:6` student_name b    \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;lgl&gt;\n1     1     4 Anna         TRUE \n2     2     5 Bob          FALSE\n3     3     6 Carlos       TRUE \n\n\nNote that: * if the vector is stored in a variable, the variable name will be the column name (e.g. column b) * you can override the column name by using new_name = the_vector as we did for the 1st and 3rd columns * if you do not, you may get an unusual column name, e.g. the 2nd column\n\nFill in the blanks to create a tibble with the column names: student, grade, pass (in that order)\n\n\nstudent &lt;- c(\"Daphne\", \"Ed\", \"Frankie\")\ncol_3 &lt;- c(TRUE, TRUE, FALSE)\ng &lt;- c(\"A\", \"C\", \"F\")\n\ntibble(\n  ____,\n  ____,\n  ____\n  )\n\n\n# hint text\n\"\"\n\n\n# hint text\n\"\"\n\n\n# solution code\nstudent &lt;- c(\"Daphne\", \"Ed\", \"Frankie\")\ncol_3 &lt;- c(TRUE, TRUE, FALSE)\ng &lt;- c(\"A\", \"C\", \"F\")\n\ntibble(\n  student,\n  grade = g,\n  pass = col_3\n  )\n\n\n# check code\ngradethis::grade_code()"
  },
  {
    "objectID": "src/book/09_computing_chapter.html#functions",
    "href": "src/book/09_computing_chapter.html#functions",
    "title": "8  More about R",
    "section": "8.4 Functions",
    "text": "8.4 Functions\nComing soon."
  },
  {
    "objectID": "src/book/09_computing_chapter.html#scope-and-the-environment",
    "href": "src/book/09_computing_chapter.html#scope-and-the-environment",
    "title": "8  More about R",
    "section": "8.5 Scope and the environment",
    "text": "8.5 Scope and the environment\nComing soon."
  },
  {
    "objectID": "src/book/09_computing_chapter.html#control-flow",
    "href": "src/book/09_computing_chapter.html#control-flow",
    "title": "8  More about R",
    "section": "8.6 Control Flow",
    "text": "8.6 Control Flow\nEarlier in this tutorial we talked about how R executes one line of code and then moves onto the next.\nBut what about if you don’t always want to go to the next line? Maybe want to jump to a different section of code or skip some lines entirely.\nIn the first interactive tutorial we mentioned functions, which are a way of saving particular lines of code so that they can be re-run. You learned how to define a function that had several input parameters, and then call it when you want to run it by passing values as arguments for each parameter. (Yes, there are a lot of words to learn for functions - you should review the first tutorial if this makes no sense!)\n\n8.6.1 If-statements\nThere are also methods of control flow for choosing whether to skip a line entirely. We can use an if statement to run one or more lines of code based on the result of a Boolean condition:\nif(some_boolean_condition_is_TRUE){\n  run the code inside these curly brackets\n}\n\nA Boolean condition is an expression that results in a Boolean value (TRUE or FALSE). If the expression evaluates to TRUE, then the code following the if statements inside the curly brackets {...} is run.\nYou are already familiar with these conditions, as you have used them in the filter() function to indicate which rows to pick from a dataframe.\n\n\nChange the value of the x variable in the first line so that the code in the if statement is run.\n\n\nx &lt;- \"ninety-nine\"\n\nif(x == 99){\n  print(\"You did it!\")\n}\n\nprint(\"This will always run.\")\n\n\n\nx &lt;- 99\n\nif(x == 99){\n  print(\"You did it!\")\n}\n\nprint(\"This will always run.\")\n\n\n# check code\ngradethis::grade_code()\n\n\n\n8.6.2 If/else-statements\nOften you may want to do one thing if a condition is TRUE, and something else if it’s not. In this case you can put an else{...} block after the if{...} block:\nif(some_boolean_condition_is_TRUE){\n  if TRUE, run the code inside these curly brackets\n} else {\n  otherwise, run this instead\n}\n\nChange the Boolean value in the if parentheses so that the else block is executed instead.\n\n\nif(TRUE){\n  print(\"the condition was TRUE\")\n} else{\n  print(\"the expression was FALSE\")\n}\n\n\n# hint text\n\"\"\n\n\n# hint text\n\"\"\n\n\nif(FALSE){\n  print(\"the condition was TRUE\")\n} else{\n  print(\"the expression was FALSE\")\n}\n\n\n# check code\ngradethis::grade_code()\n\nIn general you won’t want to put just TRUE or FALSE in the parentheses in real world code, because it will always execute one of the blocks or the other - however it is a valid Boolean expression!"
  },
  {
    "objectID": "src/book/09_computing_chapter.html#loops",
    "href": "src/book/09_computing_chapter.html#loops",
    "title": "8  More about R",
    "section": "8.7 Loops",
    "text": "8.7 Loops\nSometimes you want to run a particular piece of code over and over again (after all, do simple things repeatedly is what computers are best at).\nTo do this we need to use a loop.\n\n8.7.1 For loops\nThe most common type of loop in R is the for loop.\nThe idea behind the for loop is that “for every thing in a group of things, run some code”.\nIn R code, we would write this as:\nfor(thing in many_things){\n  some code to run\n}\nFor example, you could loop through a vector of numbers, and print out each number:\n\nfor(x in 1:10){\n  print(x)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\n\nNote that on each iteration of the loop we update the variable x (or whatever you choose to call it) and that variable can be used in the code inside the for loop’s code block {...}\n\nFill in the blank in the if statement’s condition so that only even numbers are printed out. (Remember that an even number divided by 2 will have have a remainder of 0.)\n\n\nfor(x in 1:10){\n  if(_____){\n    print(x)\n  }\n}\n\n\n# hint text\n\"\"\n\n\n# hint text\n\"\"\n\n\n# solution code\nfor(x in 1:10){\n  if(x %% 2 == 0){\n    print(x)\n  }\n}\n\n\n# check code\ngradethis::grade_code()\n\n\n\n8.7.2 Vectorization\nWhen possible, we should try to work on entire vectors at once rather than looping over a vector with for loops.\nThis is because R will iterate through a loop one step at a time, whereas it can operate on multiple elements of a vector at the same time, so vectorized code is much faster.\nWe do not have to worry about this too much, as we are working on small datasets where small speed increases are not noticeable - however, much of the the tidyverse functions we have learned are already optimized to work on vectors.\nThere are also situations where we have to use loops rather than vectorized operations (i.e. if one calculation depends on the result of the previous). However, if you are working on large datasets in R in the future, and your code is running too slowly, see if there is a way to speed it up by applying an operation to entire vectors at a time (rather than looping through a vector)."
  },
  {
    "objectID": "src/book/09_computing_chapter.html#installing-r-packages",
    "href": "src/book/09_computing_chapter.html#installing-r-packages",
    "title": "8  More about R",
    "section": "8.8 Installing R packages",
    "text": "8.8 Installing R packages\nComing soon."
  },
  {
    "objectID": "src/book/11_inference_chapter.html#what-is-inference",
    "href": "src/book/11_inference_chapter.html#what-is-inference",
    "title": "9  Inference",
    "section": "9.1 What is inference?",
    "text": "9.1 What is inference?\nThe world is an uncertain place. If you look outside in the morning and notice dark clouds, then you might infer that it is likely to rain that day.\nIn this chapter we will be learning about statistical inference, which is the idea that if we collect some data from the real world, then we can use it to infer other facts about the world (such as the processes that generated that data, or the population that our observations came from).\n\n9.1.1 Probability versus inference\nWhen things are uncertain, we often talk about the probability that an event will occur (such as the high probability that it might rain on a cloudy day, or the low probability that the Washington Wizards will win the NBA Championship this year).\nMathematically, probability is about making predictions about the future. If we know the probability of different events or observations, then we can predict the likelihood of different outcomes. If I tell you that I have a fair coin, you know that there is a 50% chance of either heads or tails, and so you can calculate the probability of getting 6 heads if I flip the coin 10 times.\nBy contrast, statistical inference is about the understanding the past. In inference we are typically given a sample of data, but we don’t know exactly how the data was generated. This is how things tend to work in both real life and in science. You observe that I get 6 heads from 10 coin flips, but you don’t know if the coin was fair or not. Inference allows you to calculate the likelihood that the coin was fair.\nThus we need to know a little bit about probability to do statistical inference. Fortunately, everything we need to know for this chapter is fairly intuitive:\n\nA probability has to be between 0 and 1. A probability of 0.5 means that something happens half of the time; a probability of 1 means that it happens all of the time!\nIn informal settings (such as weather forecasts) we sometimes talk about probabilities as percentages. You can multiply a probability by 100 to get it as a percentage. For example, a probability of 0.5 is equivalent to a 50% chance that something will happen."
  },
  {
    "objectID": "src/book/11_inference_chapter.html#distributions",
    "href": "src/book/11_inference_chapter.html#distributions",
    "title": "9  Inference",
    "section": "9.2 Distributions",
    "text": "9.2 Distributions\n\n9.2.1 Data sampling\n\n\nSlides: PDF\nBefore we can do any inference, we need to be clear on (1) what data we are using to make our inferences, and (2) what other data those inferences then apply to.\nTypically we analyze a sample of data (e.g. a group of people, or a series of coin flips). This sample is either:\n\nDrawn from a population of all possible observations (e.g. our sample of people is drawn from a larger population of people).\nGenerated by some random process (such as flipping a coin).\n\n\nWe then use the sample to make inferences about the population or process.\nWe also need to distinguish between statistics that we calculate from the sample, and the true value of that statistic from in the total population. If I collect heights from a sample of people, I can then calculate a statistic such as the mean - we would call this the sample mean. However, there is also a population mean that is probably different, since we might have slightly more tall or short people in our sample than in the total population.\nWhen we collect samples, we always hope that our sample is representative of the broader population. If it is, then we should be able to make accurate inferences.\n\n\n9.2.2 Sampling strategies and how it can go wrong\nThe best way to create a sample is to first decide what your population is, and then randomly sample members of that population.\nIf you are interested in the entire population of the USA, for example, then you would want to put every American’s name in a (virtual) hat, and then draw a sample of those names.\nOf course, there are problems with this! You might not know everyone in your population, and you might not be able to collect data from every member of the sample (for example, it’s usually unethical to force people to take part in a survey against their will). If your sample is not completely random, then it is unlikely to be representative of the population.\nThe alternative approach is to start with the sample that you have, and calculate the largest population that we can generalize to. Let’s image we measure the heights 100 male students sampled randomly at George Mason University.\nCommon sampling biases: * self-selected * convenience\nMany statistical analyses have gone astray when they generalize to a broader population that they should have done.\n\n\n9.2.3 Population-wide censuses\n\n\n9.2.4 Quantifying data distributions\n\n\nSlides: PDF\n\n\nSlides: PDF\nFill in the ellipses (...) to create a boxplot of the Sepal.Length variable from the iris dataset.\n\n\n9.2.5 Probability mass functions\n\n\nSlides: PDF"
  },
  {
    "objectID": "src/book/11_inference_chapter.html#hypothesis-testing",
    "href": "src/book/11_inference_chapter.html#hypothesis-testing",
    "title": "9  Inference",
    "section": "9.3 Hypothesis testing",
    "text": "9.3 Hypothesis testing\n\n9.3.1 Gender discrimination case study\n\n\nSlides: PDF\n\n\n9.3.2 A hypothesis test as a court trial\n\n\nSlides: PDF\n\n\n9.3.3 A manual simulation of the gender discrimination experiment\n\n\nSlides: PDF\n\n\n9.3.4 Simulating the gender discrimination experiment in R\n\n\nSlides: PDF\n\n\n9.3.5 One-sided hypothesis tests using infer\n\n\nSlides: PDF"
  },
  {
    "objectID": "src/book/17_inference_advanced_chapter.html#statistical-inference-review",
    "href": "src/book/17_inference_advanced_chapter.html#statistical-inference-review",
    "title": "12  More Statistics",
    "section": "12.1 Statistical Inference Review",
    "text": "12.1 Statistical Inference Review\n\n12.1.1 Video overview\nThis video reviews the inference material covered in the first module.\n\n\nSlides: PDF\n\n\n12.1.2 Test your understanding\n\n\nquestion(\n  \"You give sick patients either a drug or a placebo, and you measure whether they die or survive. This is stored in 2 variables, `treatment` and `outcome`, which are both categorical. What are your explanatory and response variables?\",\n  answer(\"response = `treatment`, explanatory = `outcome`\"),\n  answer(\"response = `outcome`, explanatory = `treatment`\", correct = TRUE),\n  answer('response = `\"survived\"`, explanatory = `\"drug\"`'),\n  answer('response = `\"survived\"`, explanatory = `\"placebo\"`'),\n  allow_retry = TRUE\n)\n\n\nquestion(\n  \"In a particular hypothesis test, we generate 10,000 permutations of our original data. 200 of them have a test statistic more extreme than our observed statistic. What is the p-value?\",\n  answer(\"0\"),\n  answer(\"0.01\"),\n  answer(\"0.02\", correct = TRUE, message=\"The p-value is the probability that a value as or more extreme than the observed statistic came from the null distribution, which equivalent to the fraction of simulations more extreme than the observed statistic. This is 200/10,000 = 0.02\"),\n  answer(\"0.05\"),\n  answer(\"0.1\"),\n  answer(\"0.2\"),\n  answer(\"0.5\"),\n  answer(\"1\"),\n  answer(\"2\"),\n  answer(\"5\"),\n  answer(\"50\"),\n  allow_retry = TRUE\n)\n\n\n\n12.1.3 Supplementary reading\nThese two chapters provide a good review of the original statistical inference material that we covered in the first inference module. You should review them before starting this week’s assignment:\n\nStatistical Inference via Data Science by Chester Ismay and Albert Kim (available online at: https://moderndive.com/)\n\nChapter 7: Sampling - https://moderndive.com/7-sampling.html\nChapter 9: Hypothesis testing - https://moderndive.com/9-hypothesis-testing.html\n\n\nOn a lighter note, you can get an animated explanation of a hypothesis test with alpacas here: https://www.jwilber.me/permutationtest/\n\n\n12.1.4 Code review\nIn the first inference module, we used the infer package to simulate the null distribution.\nWe ran 10,000 random permutations to shuffle up the values of the response and explanatory variables. This random shuffling ensures that we simulate a distribution where there is no relationship between the two variables.\n&lt;DATAFRAME&gt; %&gt;%\n  specify(&lt;RESPONSE&gt; ~ &lt;EXPLANATORY&gt;) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(10000, type = \"permute\") %&gt;%\n  calculate(stat = \"...\", order = c(..., ...))\n\nThe specify function defines the response and explanatory variables.\nThe hypothesize function declares what the null hypothesis is between those variables. \"independence\" means that there is no relationship between them.\nThe generate function is where the simulations are actually run: we specify how many, and how to shuffle the data (in this case, using permutations).\nThe calculate functions takes the simulations and calculates a test statistic: i.e. a single value for each one (e.g. the difference in proportions, or the difference in means)."
  },
  {
    "objectID": "src/book/17_inference_advanced_chapter.html#one-sided-vs.-two-sided-tests",
    "href": "src/book/17_inference_advanced_chapter.html#one-sided-vs.-two-sided-tests",
    "title": "12  More Statistics",
    "section": "12.2 One-sided vs. two-sided tests",
    "text": "12.2 One-sided vs. two-sided tests\n\n12.2.1 Video overview\n\n\nSlides: PDF\n\n\n12.2.2 1 or 2?\n\n\nquestion(\n  \"You want to conduct a *two-sided* hypothesis test on data from an experiment comparing whether a patient survive a disease after receiving a drug or a placebo. What is your alternative hypothesis?\",\n  answer(\"The difference in proportions of patients who survive is significantly different between drug and placebo groups.\", correct = TRUE, message = \"In a two-sided test, the alternative hypothesis is that there is a difference, regardless of direction (i.e. whether the difference is positive or negative is unimportant).\"),\n  answer(\"The difference in means of patients who survive is significantly different between drug and placebo groups.\"),\n  answer(\"The difference in means of patients who survive is significantly greater in the drug group than the placebo group.\"),\n  answer(\"The difference in proportions of patients who survive is significantly greater in the drug group than the placebo group.\"),\n  allow_retry = TRUE\n)"
  },
  {
    "objectID": "src/book/17_inference_advanced_chapter.html#effect-sizes",
    "href": "src/book/17_inference_advanced_chapter.html#effect-sizes",
    "title": "12  More Statistics",
    "section": "12.3 Effect sizes",
    "text": "12.3 Effect sizes\n\n12.3.1 Video overview\n\n\nSlides: PDF"
  },
  {
    "objectID": "src/book/17_inference_advanced_chapter.html#resampling-with-permutations-versus-bootstraps",
    "href": "src/book/17_inference_advanced_chapter.html#resampling-with-permutations-versus-bootstraps",
    "title": "12  More Statistics",
    "section": "12.4 Resampling with permutations versus bootstraps",
    "text": "12.4 Resampling with permutations versus bootstraps\nComing soon."
  },
  {
    "objectID": "src/book/17_inference_advanced_chapter.html#confidence-intervals",
    "href": "src/book/17_inference_advanced_chapter.html#confidence-intervals",
    "title": "12  More Statistics",
    "section": "12.5 Confidence intervals",
    "text": "12.5 Confidence intervals\n\n12.5.1 Video overview\n\n\nSlides: PDF\n\n\n12.5.2 Questions\n\n\nquestion(\n  \"You want to conduct a hypothesis test using the `infer` package in R. How should you shuffle the data to generate a null distribution?\",\n  answer(\"Bootstraps\"),\n  answer(\"Permutations\", correct = TRUE, message = \"A permutation shuffles up the values of the explanatory and response variables, and so simulates a world in which there is no relationship between the two (i.e. the null hypothesis).\"),\n  answer(\"It doesn't matter\"),\n  allow_retry = TRUE\n)\n\n\nquestion(\n  \"You want to calculate the confidence interval around a statistic (e.g. the mean) using the `infer` package in R. How can you approximate resampling the original population?\",\n  answer(\"Bootstraps\", correct = TRUE, message = \"By taking random samples of rows from the original sample (*bootstrap resampling*), we can approximate resampling the original population.\"),\n  answer(\"It doesn't matter\"),\n  answer(\"Permutations\"),\n  allow_retry = TRUE\n)"
  },
  {
    "objectID": "src/book/17_inference_advanced_chapter.html#further-reading",
    "href": "src/book/17_inference_advanced_chapter.html#further-reading",
    "title": "12  More Statistics",
    "section": "12.6 Further reading",
    "text": "12.6 Further reading\nIf you wish to do further reading on bootstrapping and confidence intervals, here are some online book chapters on the topic. (They cover the same material, so pick the one that makes the most sense to you.)\n\nStatistical Inference via Data Science by Chester Ismay and Albert Kim\n\nChapter 8: Bootstrapping and Confidence Intervals - https://moderndive.com/8-confidence-intervals.html\n\nStatistical Modeling by Daniel Kaplan\n\nChapter 5: Confidence Intervals - https://dtkaplan.github.io/SM2-bookdown/confidence-intervals.html"
  },
  {
    "objectID": "src/book/18_modeling_advanced_chapter.html#interaction-terms",
    "href": "src/book/18_modeling_advanced_chapter.html#interaction-terms",
    "title": "13  More Models",
    "section": "13.1 Interaction terms",
    "text": "13.1 Interaction terms\n\n13.1.1 Independence and interaction\nSo far we have assumed that each term is independent: i.e. each one contributes to the response variable \\(y\\) a separate amount proportional to its coefficient.\nHowever, it is possible for variables to interact with each other:\n\\(y = m_1 x_1 + m_2 x_2 + m_3 x_1 x_2 + c\\)\nThis linear model has an interaction term: \\(x_1 x_2\\). What this means is that the contribution of either variable depends somewhat on the value of the other!\nFor example, consider an experiment where we are looking at the effect of water and sunlight on plant height. Both variables may increase a plant’s height - however they are also dependent on each other. If we keep a plant in complete darkness, then no amount of water will help it grow (and vice versa). In otherwords, the effect of either sunlight or water on plant height depends on how much of the other variable the plant is receiving.\nIt is very easy to add interaction terms to a linear model. For example, the formula above would be written something like:\ny ~ x1 + x2 + x1 * x2\nAs you can see, we just add an asterisk * between variables that we wish to have an interaction between."
  },
  {
    "objectID": "src/book/18_modeling_advanced_chapter.html#hypothesis-tests-for-models",
    "href": "src/book/18_modeling_advanced_chapter.html#hypothesis-tests-for-models",
    "title": "13  More Models",
    "section": "13.2 Hypothesis tests for models",
    "text": "13.2 Hypothesis tests for models\n\n13.2.1 Linear models and hypothesis tests\nYou may remember from our first modeling module that the tidy function reported a p-value for the model and for each explanatory variable. See the p.value columns in both of these examples:\n\nsim_model &lt;- lm(y ~ x, data=sim_df)\n\n\nsim_model %&gt;%\n  glance() %&gt;%\n  select(r.squared, p.value)\n\n# A tibble: 1 × 2\n  r.squared    p.value\n      &lt;dbl&gt;      &lt;dbl&gt;\n1     0.935 0.00000512\n\n\nAs you will remember from our inference modules, the p-value is the probability that the actual data was generated in a world in which the null hypothesis is true.\nNull hypothesis?! But we haven’t specified any hypotheses for our linear model, have we?\nIn fact, there is a null hypothesis for every linear model, although we have never formally written it down. The null hypothesis for a linear model is that there is no relationship between the response and explanatory variables. In other words, our null hypothesis is that the line of best fit is a horizontally flat line (e.g. the blue line in this plot):\n\nsim_df %&gt;%\n  ggplot() +\n  geom_point(mapping = aes(x, y)) +\n  geom_abline(slope = 0, intercept = 0, color = \"blue\") +\n  ylim(-5,25)\n\n\n\n\nIn other words, the p-value is the probability that the data came from this line. Just by looking at it, we can see that this is not very likely, and in fact the p-value is 0.000005 (or 0.0005%), i.e. statistically very unlikely.\nWe continue to use our regular significance threshold, \\(\\alpha = 0.05\\). In this case, we can reject our null hypothesis (that there is no relationship).\nHowever, hypothesis testing only tells us the probability that there is a relationship, or not. If there is a relationship, it doesn’t tell us how good it is, i.e. how well our model fits the data. For this, we need to continue to use the \\(R^2\\) value, as well as our graphs to check the 3 main assumptions of the linear model.\n\n\n13.2.2 p-values of individual variables\nThe tidy() function also reports a p-value for each variable in the model.\n\nsim_model %&gt;%\n  tidy()\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic    p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)     1.27     1.06       1.20 0.264     \n2 x               1.75     0.164     10.7  0.00000512\n\n\nFor individual variables, the null hypothesis is that each individual explanatory variable has no relationship with the response variable. In other words, our null hypothesis is that the intercept and slope are 0.\nAs we can see for this example, because the p-values of the slope is below 0.05, so we reject our null hypothesis. We find that the non-zero slope of the x variable is statistically significant. However, the intercept has a p-value of 0.26. This is greater than 0.05, so we cannot reject our null hypothesis of a zero intercept for this particular dataset.\n(This dataset was simulated with an intercept of zero, so that makes sense!)\n\nA note on scientific notation\nIn the previous examples, our p-values have been written as strange numbers, such as: 2.637853e-01\nThis is a convenient way of writing numbers that are very large or very small. We can write 1.2 million (1,200,000) as:\n\\(1.2 \\times 10^6\\)\ni.e. 1.2 times 1 million, or\n1.2e6\nwhich uses e to represent “10 to the power of”.\nFor numbers that are less that one, we can do the same thing but use a negative power of ten. For example, we can write 0.263 as:\n\\(2.63 \\times 10^{-1}\\)\nor\n2.63e-1\nbecause \\(10^{-1}\\) is 0.1"
  },
  {
    "objectID": "src/book/32_databases_chapter.html#relational-data",
    "href": "src/book/32_databases_chapter.html#relational-data",
    "title": "14  Databases",
    "section": "14.1 Relational data",
    "text": "14.1 Relational data\nA database is simply an organized way of storing data.\nThere are obviously many ways that one could choose to organize data, but a particularly common form of database is the relational database, in which data is broken up into multiple tables. In general the goal of a relational database is to avoid repeating the same piece of data in multiple rows.\nFor example, in the dataset of hobbits and addresses in the previous section, we can avoid repeating the same address for Bilbo and Frodo by splitting the addresses into a separate table. Then every hobbit who lives at a particular address gets a link to that address row in the separate address table (instead of repeatedly writing out the same address for each hobbit).\nIn addition, relational databases follow the same rules that tidy datasets have to follow:\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nRelational databases are extremely common (for example, almost every website you visit has a relational database that stores the website’s information), and learning how to work with these databases is a vital skill for every data scientist.\n\n14.1.1 Joining matching rows\nIn such cases, there are often columns in each table that link the two tables back together.\nFor example, consider these two tables:\n\n\n# A tibble: 3 × 3\n  names   age hobbit_hole\n  &lt;chr&gt; &lt;dbl&gt;       &lt;dbl&gt;\n1 Bilbo   111           1\n2 Frodo    50           1\n3 Sam      38           2\n\n\n# A tibble: 2 × 2\n     id address                \n  &lt;dbl&gt; &lt;chr&gt;                  \n1     1 Bag End, Hobbiton      \n2     2 3 Bagshot Row, Hobbiton\n\n\nThe first table contains three hobbits. However, instead of listing out their addresses, we have instead recorded a number that corresponds to the id column of the second table.\nBy matching the hobbit_hole column with the id column, we can see that Bilbo and Frodo both live at Bag End whereas Sam lives at 3 Bagshot Row.\nSome terminology:\n\nIn the mathematical theory of databases, each of these tables would be called a “relation”, hence the name relational data for data stored across multiple tables in this fashion.\nThe id column in the table of addresses is an example of a key. A key is any column (or columns) that provide a unique way of identifying every row in a table.\nThe hobbit_hole column in the table of hobbits is a foreign key. This links each hobbit to the identifying key in a different (i.e. “foreign”) table.\n\nOf course, we could just have recorded this data as a single table! For example:\n\n\n# A tibble: 3 × 3\n  names   age hobbit_hole            \n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;                  \n1 Bilbo   111 Bag End, Hobbiton      \n2 Frodo    50 Bag End, Hobbiton      \n3 Sam      38 3 Bagshot Row, Hobbiton\n\n\nWhat are the advantages to splitting data over multiple tables?\n\nOne reason is to avoid repeating certain values. For example, we have written the address Bag End twice. If we split addresses into a separate table then we only need to write it once. This means that:\n\nWe need less space to store our data.\nWe can reduce errors and inconsistencies (for example, we won’t end up with two different spellings of Bag End by accident (Bag End vs. Bag-End)).\nUpdating the dataset is easier (if we later decided that Bag End did need to be spelled with a hyphen then we would only need to update it in one place - otherwise we might easily update it for one hobbit and forget to do so for another).\n\n\nOf course, sometimes we need to combine data from multiple tables into a single dataframe for analysis.\nTo do this we need to join the separate datasets back together, typically using by using columns that link to connected rows in different tables (such as keys and foreign keys).\nThere are several different ways to join tables, which will link rows in different ways.\nTo illustrate these different joins let us imagine that we are ecologists in a similar world to that inhabited by the hobbits from the previous section. We have gathered the following two tables of data about different species inhabiting this unusual world.\n\nspecies &lt;- tibble(\n  species = c(\"Giant Eagle\", \"Goblin\", \"Goblin\", \"Giant Spider\", \"Balrog\"),\n  location = c(2, 2, 3, 1, NA)\n)\n\nsightings &lt;- tibble(\n  location_id = c(1,2,3,4),\n  name = c(\"Mirkwood Forest\", \"Misty Mountains\", \"Mordor\", \"The Shire\")\n)\n\nOne important thing to note is that there are some rows in each table that do not have a match in the other table.\n\nThe default type of join is an inner join (if somebody ever says just “join” then they are usually referring to an inner join).\nAn inner join matches rows that have the same values in some column(s). Any rows in either table that do not have a match are omitted.\nWe will use the inner_join() function from the dplyr package which has the following signature:\ninner_join(x, y, by=NULL)\n\nx and y are two dataframes that we wish to join.\nThe by parameter specifies which columns to use for matching rows. If we do not specify it then R will automatically match any columns with the same names. It is a good idea to always specify it to make sure that we are only joining on the columns that we want to match!\n\nNote that: * We are piping in the species tibble to the inner_join() function, but we could have written it inside the function instead. * The argument to by is a named vector specifying the names of the columns. * \"location_id\" is the only value in this 1 item vector, but we have also named this item as \"location\". * R will look for the column \"location\" in the first dataframe (which is species in this example), and location_id in the second dataframe (sightings).\n\nspecies %&gt;%\n  inner_join(sightings, by=c(\"location\" = \"location_id\"))\n\n# A tibble: 4 × 3\n  species      location name           \n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;          \n1 Giant Eagle         2 Misty Mountains\n2 Goblin              2 Misty Mountains\n3 Goblin              3 Mordor         \n4 Giant Spider        1 Mirkwood Forest\n\n\nIn our output we only have rows that had a matching row in the other dataframe (i.e. we dropped the Balrog row from the species dataframe and The Shire from the sightings table).\nAlso, note that the Misty Mountains now appear twice in the output, even though there is only one Misty Mountains row in the sightings table."
  },
  {
    "objectID": "src/book/32_databases_chapter.html#database-software-and-sql",
    "href": "src/book/32_databases_chapter.html#database-software-and-sql",
    "title": "14  Databases",
    "section": "14.2 Database software and SQL",
    "text": "14.2 Database software and SQL\nYou could create your own simple version of a relational database by storing each of your tables in a separate file on your computer’s harddrive. For simple applications this is a valid solution - however in more complex projects you start to run into problems with ensuring that tables contain the corret data, or that different programs can simultaneously access the data (and don’t accidentally overwrite an update to a file created by another computer program), or simply with efficiently wrangling large amounts of data.\nWe can solve all of these problems by using a dedicated database program that takes of care of storing our data for us. In addition to storing the data for us, these database management systems (DMS) will also allow us to query the data (i.e. access it) and will run those queries in an efficient manner.\nRelational databases all use a special programming language for accessing their data. This programming language is called SQL.\n\nSQL stands for Structured Query Language. It is properly pronounced using by spelling out the acronym: “ess-kew-ell”. However, some people pronounce it as “sequel”.\n\nFortunately we do not need to learn SQL for this class (although you should learn SQL at some point if you wish to do more work with data in the future, since most of it will be stored in databases). Instead we can interact with relational databases using the data wrangling functions that we have already learned.\nI.e. we can use functions like select(), filter(), and inner_join() directly on a relational database and R will translate these into the SQL programming language for us!\n\n14.2.1 Connecting to a database.\nSince a database management system is a separate software program, we need first need to set up a connection to that database software from R.\nTo do this we can use an R package called DBI. In these examples we will connect to a database program called SQLite. (There are many other relational database systems (MySQL, PostgreSQL, etc.) but we could connect to those with very similar code.)\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"my_database_name.sqlite\")\nWhat is this code doing?\n\nThe dbConnect() function from the DBI package sets up the connection to the database.\n\nNote that we have used the :: operator in the general form package_name::function to access the function from a particular package. This way we do not have to load the package first with the library() function.\n\nThen we use the SQLite() function from the `RSQLite package to specify that this database uses the SQLite dabase management system.\nFinally we have to specify the location of the database. SQLite stores databases as a file on your computer, so here we have just written the name of such a file: \"my_database_name.sqlite\".\n\n\n\n14.2.2 Listing tables\nWe can get a list of all the tables in a database by running this DBI package function on our new connection:\nDBI::dbListTables(con)\n\n\n14.2.3 Connecting to a database table\nTo access a table in our database with our standard data wrangling functions, we need to create a new R variable that points to that table. We do this with the tbl() function from the dbplyr package:\nsome_table &lt;- tbl(con, \"table_name\")\nThis code creates a new variable called some_table that allows us to access a particular database table.\nYou will need to create a new variable in the same way for every database table that you wish to access from R.\n\nNote that the dbplyr package is different to dplyr:\n\ndplyr contains the data wrangling functions that we have used to interact with R dataframes (e.g. filter(), select(), etc.).\ndbplyr allows us to use these data wrangling functions on databases by translating the functions into SQL, and then converting the database output back into an R dataframe.\n\n\n\n\n14.2.4 An example: selecting columns\nWe can now use our data wrangling functions on the database table just as if it was an R dataframe.\nFor example, to select() columns:\nexample_query &lt;- some_table %&gt;%\n  select(example_column_1, example_column_2)\nOne difference, however, is that this code will not create a new dataframe. Instead it creates a SQL query that can be run on the database (in the future) to create a new dataframe.\nWe have stored this query in a new variable called example_query. If we wish, we can view what the SQL query looks like by running the show_query() function:\nexample_query %&gt;%\n  show_query()\nTo run the query and return a dataframe, you need to run the collect() function on the query:\nexample_df &lt;- example_query %&gt;%\n  collect()\nThis will retrieve the data from the database and store it as an R dataframe in a new variable called example_df."
  },
  {
    "objectID": "src/book/32_databases_chapter.html#joining-data-from-relational-database-tables",
    "href": "src/book/32_databases_chapter.html#joining-data-from-relational-database-tables",
    "title": "14  Databases",
    "section": "14.3 Joining data from relational database tables",
    "text": "14.3 Joining data from relational database tables\nIn the More Data Wrangling chapter, we learned that we could join separate tables of data together by matching rows with\n\n14.3.1 Outer joins\nSometimes we want to preserve a row from one (or both) of the tables we are joining even if there is no match with the other table. These are called outer joins, and there are three types depending on which table(s) we want to keep unmatched rows from:\n\nA left outer join (or just “left join”) keeps all rows from the table on the left (i.e. the first dataframe we name).\nA right outer join (aka “right join”) keeps the rows in the table on the right instead (the second dataframe we name).\nA full outer join (“full join”) keeps all rows from both tables.\n\nAny rows that are kept but not matched to a row in the other table will just have missing data in the other table’s columns.\nThe process for doing these joins is very similar to an inner join.\n\n14.3.1.1 Left outer joins\n\nspecies %&gt;%\n  left_join(sightings, by=c(\"location\" = \"location_id\"))\n\n# A tibble: 5 × 3\n  species      location name           \n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;          \n1 Giant Eagle         2 Misty Mountains\n2 Goblin              2 Misty Mountains\n3 Goblin              3 Mordor         \n4 Giant Spider        1 Mirkwood Forest\n5 Balrog             NA &lt;NA&gt;           \n\n\n\n\n14.3.1.2 Right outer joins\n\nspecies %&gt;%\n  right_join(sightings, by=c(\"location\" = \"location_id\"))\n\n# A tibble: 5 × 3\n  species      location name           \n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;          \n1 Giant Eagle         2 Misty Mountains\n2 Goblin              2 Misty Mountains\n3 Goblin              3 Mordor         \n4 Giant Spider        1 Mirkwood Forest\n5 &lt;NA&gt;                4 The Shire      \n\n\n\n\n14.3.1.3 Full outer joins\n\nspecies %&gt;%\n  full_join(sightings, by=c(\"location\" = \"location_id\"))\n\n# A tibble: 6 × 3\n  species      location name           \n  &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;          \n1 Giant Eagle         2 Misty Mountains\n2 Goblin              2 Misty Mountains\n3 Goblin              3 Mordor         \n4 Giant Spider        1 Mirkwood Forest\n5 Balrog             NA &lt;NA&gt;           \n6 &lt;NA&gt;                4 The Shire"
  },
  {
    "objectID": "src/book/32_databases_chapter.html#non-relational-databases",
    "href": "src/book/32_databases_chapter.html#non-relational-databases",
    "title": "14  Databases",
    "section": "14.4 Non-relational databases",
    "text": "14.4 Non-relational databases"
  },
  {
    "objectID": "src/book/references.html",
    "href": "src/book/references.html",
    "title": "References",
    "section": "",
    "text": "Baker, Monya. 2016. “1,500 Scientists Lift the Lid on\nReproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a."
  },
  {
    "objectID": "src/book/A_faqs_appendix.html#rstudio",
    "href": "src/book/A_faqs_appendix.html#rstudio",
    "title": "Appendix A — Frequently Asked Questions",
    "section": "A.1 RStudio",
    "text": "A.1 RStudio\n\nA.1.1 RStudio error: Error occurred during transmission\nIf you get this error message when logging into the GMU RStudio Server:\n\n\n\nRStudio error message: Error occurred during transmission\n\n\nSolution\n\nGo to https://rstudio.cos.gmu.edu/home\nClick the “Quit” button (near the top of the page)\nThen you should be able to reopen a project."
  },
  {
    "objectID": "src/book/A_faqs_appendix.html#cannot-push-to-github-authentication-failed",
    "href": "src/book/A_faqs_appendix.html#cannot-push-to-github-authentication-failed",
    "title": "Appendix A — Frequently Asked Questions",
    "section": "A.2 Cannot push to GitHub: “Authentication failed”",
    "text": "A.2 Cannot push to GitHub: “Authentication failed”\nYou might find yourself with an error like this when you try to clone a repository from GitHub into RStudio, or push commits back to GitHub:\nremote: Support for password authentication was removed on August 13, 2021.\nremote: Please see https://docs.github.com/en/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.\nfatal: Authentication failed for 'https://github.com/mason-cds101/final-project-dominicwhite/'\nThis usually means that either:\n\nYou have not correctly created and set your GitHub token (as per the instructions in step 4 Section Section 2.4.1). If this is the first time you are trying to clone from or push to GitHub, this is probably the reason.\nYour previous token has expired, and you will need to create a new one and store it in RStudio. If your token used to allow you to clone from and push to GitHub but has suddenly stopped working, then this is probably the reason.\n\nIn both cases, repeat Step 4 in Section Section 2.4.1."
  },
  {
    "objectID": "src/book/A_faqs_appendix.html#packages",
    "href": "src/book/A_faqs_appendix.html#packages",
    "title": "Appendix A — Frequently Asked Questions",
    "section": "A.3 Packages",
    "text": "A.3 Packages\n\nA.3.1 Installing an older version of a package\nTo install an older version of a package (e.g. the lmvar package), you can run these two lines of code, making sure to replace the name of the package and the version that you want to install:\nrequire(remotes)\ninstall_version(\"lmvar\", version = \"1.5.2\", repos = \"http://cran.us.r-project.org\")"
  },
  {
    "objectID": "src/book/B_additional_setup_appendix.html#sec-create-new-rstudio-project",
    "href": "src/book/B_additional_setup_appendix.html#sec-create-new-rstudio-project",
    "title": "Appendix B — Additional Software Set-up",
    "section": "B.1 How to clone a GitHub repository into RStudio",
    "text": "B.1 How to clone a GitHub repository into RStudio\n\nB.1.1 In RStudio Cloud\n\nFrom your homepage, click on the New Project button in the top right of the screen (Figure B.1)\n\n\n\n\nFigure B.1: The New Project Button in RStudio Cloud\n\n\n\nIn the drop-down menu, click on the option that says “New Project from Git Repository” (Figure B.2).\n\n\n\n\nFigure B.2: The menu of different ways to create a new project.\n\n\n\nIn the pop-up window, paste in the URL (web address) of the GitHub repository that you wish to open in RStudio (Figure B.3).\n\n\n\n\nFigure B.3: An example of the kind of GitHub repository URL (web address) you need to type in.\n\n\n\n\nB.1.2 In RStudio Desktop\n\nClick on the New Project option in the Files dropdown menu).\nIn the New Project wizard that pops up, click on the option that says “Version Control” (Figure B.4)\n\n\n\n\nFigure B.4: Step 1 of RStudio’s New Project wizard.\n\n\n\nOn the next page of the wizard, click on the “Git” option (Figure B.5)\n\n\n\n\nFigure B.5: Step 2 of RStudio’s New Project wizard.\n\n\n\nOn the final page of the wizard (Figure B.6), fill in the details for the GitHub repository you wish to “clone” (i.e. download), and where to download it to:\n\n\n\n\nFigure B.6: Step 3 of RStudio’s New Project wizard.\n\n\n\nIn the first field (“Repository URL”) copy-and-paste the web address of the GitHub repository’s homepage.\nThe second field will be the name of the folder created on your computer to hold all the files you are downloading from the GitHub repository. It may auto-fill with the repository’s name - you can also type something in, or change it to a different folder name if you prefer.\nThe third field is the name of the parent folder that will hold the folder above. I would recommend organizing related projects (e.g. the projects from this book) in a single parent folder so that they are easy to find. If you click “Browse” you can choose or create a parent folder to hold all your project folders.\n\nThen click “Create Project”."
  },
  {
    "objectID": "src/book/B_additional_setup_appendix.html#sec-rstudio-github-linux-connection",
    "href": "src/book/B_additional_setup_appendix.html#sec-rstudio-github-linux-connection",
    "title": "Appendix B — Additional Software Set-up",
    "section": "B.2 Connecting RStudio to GitHub on Linux",
    "text": "B.2 Connecting RStudio to GitHub on Linux\n\nFirst, go to RStudio and open the tab in the left hand pane called Terminal. If you do not see a Terminal tab, then you can create one from the top menu of RStudio Desktop by going to “Tools &gt; Terminal &gt; New Terminal”.\nIn this terminal, set your GitHub username by running this line, making sure to replace your name inside the quotation marks:\ngit config --global user.name \"Your Name Here\"\nThen run this commend, again making sure to replace the email inside the quotation marks with the same email you used to sign up for GitHub:\ngit config --global user.email \"you@emailHost.com\"\nI would also recommend running one final line in the Terminal (this will enable your computer to store your GitHub login details - otherwise you will be typing them in a lot).\ngit config --global credential.helper store\nThen go to the Console tab (which should be next to the Terminal), and copy and paste these lines of R code one at a time:\ninstall.packages(\"usethis\",\"gitcreds\")\nthen this line (which will open a GitHub web page - see below for what to fill in)\nusethis::create_github_token()\n\nOn the token webpage that appears, make sure that you are creating a “Classic token”, and not a “Fine-grained” token. Then you will need to set the following options:\n\nIn the Note field, write something that indicates where this token will be used, e.g. RStudio.\nFor the expiration date, pick a date about in the future after which you will no longer need the token. E.g. if you are following these instructions for a class, pick a date after the end of the semester.\nYou should not select no expiration date - that is a security risk.\n\nYou can leave all the checked scopes as the defaults, and then scroll down to the green Generate token button at the bottom of the webpage and click it.\nThe next page that appears will display a token, a random series of letters and numbers that is basically a temporary password that you can use to authorize a restricted set of activities on your GitHub account (without having to share your master password with RStudio). You will never see this token again after you leave this page, so don’t close the webpage until you have finished this section, or you will have to create an entirely new token.\nReturn to the Console tab in RStudio, and run this line:\ngitcreds::gitcreds_set()\nAt the prompt, copy and paste the token from GitHub and click enter.\n(If you ever need to replace the token, just run gitcreds::gitcreds_set() in the RStudio Console again.)"
  },
  {
    "objectID": "src/book/B_additional_setup_appendix.html#sec-vscode-setup-appendix",
    "href": "src/book/B_additional_setup_appendix.html#sec-vscode-setup-appendix",
    "title": "Appendix B — Additional Software Set-up",
    "section": "B.3 VS Code IDE Set-up",
    "text": "B.3 VS Code IDE Set-up"
  }
]